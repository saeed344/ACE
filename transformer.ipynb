{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8850732,"sourceType":"datasetVersion","datasetId":5298654}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-07T08:59:21.587422Z","iopub.execute_input":"2024-07-07T08:59:21.587748Z","iopub.status.idle":"2024-07-07T08:59:22.563609Z","shell.execute_reply.started":"2024-07-07T08:59:21.587720Z","shell.execute_reply":"2024-07-07T08:59:22.562634Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/ace-dataset/ACE_dataset.csv\n/kaggle/input/ace-dataset/ACE_dataset.fasta\n/kaggle/input/ace-dataset/features/ACE_ASDC.csv\n/kaggle/input/ace-dataset/features/opf_7bit_type_1_features.csv\n/kaggle/input/ace-dataset/features/opf_7bit_type_2_features.csv\n/kaggle/input/ace-dataset/features/esmv1_feat_ACE.csv\n/kaggle/input/ace-dataset/features/ACE_embeddings_prot_t5_xl_bfd.csv\n/kaggle/input/ace-dataset/features/esm2_t6_8M_feat_ACE.csv\n/kaggle/input/ace-dataset/features/opf_7bit_type_3_features.csv\n/kaggle/input/ace-dataset/features/opf_10bit_features.csv\n/kaggle/input/ace-dataset/features/ACE_AAC.csv\n/kaggle/input/ace-dataset/auto_enco_feat/AEDN-500.csv\n/kaggle/input/ace-dataset/auto_enco_feat/AEDN-300.csv\n/kaggle/input/ace-dataset/auto_enco_feat/AEDN-50.csv\n/kaggle/input/ace-dataset/auto_enco_feat/AEDN-400.csv\n/kaggle/input/ace-dataset/auto_enco_feat/AEDN-450.csv\n/kaggle/input/ace-dataset/auto_enco_feat/AEDN-350.csv\n/kaggle/input/ace-dataset/auto_enco_feat/AEDN-250.csv\n/kaggle/input/ace-dataset/auto_enco_feat/AEDN-200.csv\n/kaggle/input/ace-dataset/auto_enco_feat/AEDN-100.csv\n/kaggle/input/ace-dataset/auto_enco_feat/AEDN-150.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom sklearn.preprocessing import scale\nfrom keras.saving import register_keras_serializable\n\n# Load data\npath = \"/kaggle/input/ace-dataset/auto_enco_feat/\"\ndata_ = pd.read_csv(path + 'AEDN-100.csv')\n\ndata_np = np.array(data_)\ndata = scale(data_np[:, 1:])\n\nlabel1 = np.ones((394, 1))  # Value can be changed\nlabel2 = np.zeros((626, 1))\nlabels = np.append(label1, label2)\n\n# Define the positional encoding function\ndef positional_encoding(positions, d):\n    pos = np.arange(positions)[:, np.newaxis]\n    k = np.arange(d)[np.newaxis, :]\n    i = k // 2\n    angle_rads = pos / (10000 ** (2 * i / d))\n\n    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n\n    pos_encoding = angle_rads[np.newaxis, ...]\n\n    return tf.cast(pos_encoding, dtype=tf.float32)\n\n@register_keras_serializable()\nclass TransformerModel(keras.Model):\n    def __init__(self, input_vocab_size, d_model, num_heads, ff_dim, rate=0.1, maxlen=50):\n        super(TransformerModel, self).__init__()\n\n        self.embedding = layers.Embedding(input_vocab_size, d_model)\n        self.PE = positional_encoding(maxlen, d_model)\n        self.transformer_block = TransformerBlock_Encode(d_model, num_heads, ff_dim, rate)\n        self.transformer_block2 = TransformerBlock_decode(d_model, num_heads, ff_dim, rate)\n        self.flatten = layers.Flatten()\n        self.fc1 = layers.Dense(512, activation=\"relu\")\n        self.fc3 = layers.Dense(256, activation=\"relu\")\n        self.fc2 = layers.Dense(1, activation=\"sigmoid\")\n\n    def call(self, inputs, training=None):\n        x = self.embedding(inputs)\n        y = self.transformer_block(x, training=training)\n        x = self.transformer_block2(x, y, y, training=training)\n        x = self.flatten(x)\n        x = self.fc1(x)\n        x = self.fc3(x)\n        return self.fc2(x)\n    \n    @classmethod\n    def from_config(cls, config):\n        return cls(**config['config'])\n\nclass TransformerBlock_decode(layers.Layer):\n    def __init__(self, d_model, num_heads, ff_dim, rate=0.1):\n        super(TransformerBlock_decode, self).__init__()\n\n        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n        self.att1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n        self.ffn = keras.Sequential(\n            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(d_model)]\n        )\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n        self.dropout1 = layers.Dropout(rate)\n        self.dropout2 = layers.Dropout(rate)\n        self.dropout3 = layers.Dropout(rate)\n\n    def call(self, inputs, q, k, training=None):\n        attn_output = self.att(inputs, inputs, inputs)\n        out1 = self.layernorm1(inputs + self.dropout1(attn_output, training=training))\n\n        attn_output1 = self.att1(q, k, out1)\n        out2 = self.layernorm2(out1 + self.dropout2(attn_output1, training=training))\n\n        ffn_output = self.ffn(out2)\n        return self.layernorm3(out2 + self.dropout3(ffn_output, training=training))\n\n\nclass TransformerBlock_Encode(layers.Layer):\n    def __init__(self, d_model, num_heads, ff_dim, rate=0.1):\n        super(TransformerBlock_Encode, self).__init__()\n        self.con = layers.Conv1D(256, 5, padding='same')\n        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n        self.ffn = keras.Sequential(\n            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(d_model)]\n        )\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n        self.dropout1 = layers.Dropout(rate)\n        self.dropout2 = layers.Dropout(rate)\n\n    def call(self, inputs, training=None):\n        inputs = self.con(inputs)\n        attn_output = self.att(inputs, inputs, inputs)\n        out1 = self.layernorm1(inputs + self.dropout1(attn_output, training=training))\n\n        ffn_output = self.ffn(out1)\n        return self.layernorm2(out1 + self.dropout2(ffn_output, training=training))\n\n# Define the model parameters\ninput_vocab_size = 100  # Replace with the actual vocabulary size\nd_model = 256\nnum_heads = 4\nff_dim = 128\n\nmodel = TransformerModel(input_vocab_size, d_model, num_heads, ff_dim)\n\n# Convert data to tensor\ndata_tensor = tf.convert_to_tensor(data, dtype=tf.float32)\n\n# Pass through the transformer encoder\ntransformed_features = model(data_tensor)\n\n# Save transformed features\ntransformed_features = transformed_features.numpy()\ntransformed_df = pd.DataFrame(transformed_features, columns=[f'feature_{i}' for i in range(transformed_features.shape[1])])\ntransformed_df.to_csv('transformed_data.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-07T09:00:25.917235Z","iopub.execute_input":"2024-07-07T09:00:25.917615Z","iopub.status.idle":"2024-07-07T09:00:26.952531Z","shell.execute_reply.started":"2024-07-07T09:00:25.917587Z","shell.execute_reply":"2024-07-07T09:00:26.951408Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom sklearn.preprocessing import scale\nfrom keras.saving import register_keras_serializable\n\n# Load data\npath = \"/kaggle/input/ace-dataset/auto_enco_feat/\"\ndata_ = pd.read_csv(path + 'AEDN-100.csv')\n\ndata_np = np.array(data_)\ndata = scale(data_np[:, 1:])\n\nlabel1 = np.ones((394, 1))  # Value can be changed\nlabel2 = np.zeros((626, 1))\nlabels = np.append(label1, label2)\n\n# Define the positional encoding function\ndef positional_encoding(positions, d):\n    pos = np.arange(positions)[:, np.newaxis]\n    k = np.arange(d)[np.newaxis, :]\n    i = k // 2\n    angle_rads = pos / (10000 ** (2 * i / d))\n\n    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n\n    pos_encoding = angle_rads[np.newaxis, ...]\n\n    return tf.cast(pos_encoding, dtype=tf.float32)\n\n@register_keras_serializable()\nclass TransformerModel(keras.Model):\n    def __init__(self, input_vocab_size, d_model, num_heads, ff_dim, rate=0.1, maxlen=100):\n        super(TransformerModel, self).__init__()\n\n        self.embedding = layers.Embedding(input_vocab_size, d_model)\n        self.PE = positional_encoding(maxlen, d_model)\n        self.transformer_block = TransformerBlock_Encode(d_model, num_heads, ff_dim, rate)\n        self.transformer_block2 = TransformerBlock_decode(d_model, num_heads, ff_dim, rate)\n        self.flatten = layers.Flatten()\n        self.fc1 = layers.Dense(512, activation=\"relu\")\n        self.fc2 = layers.Dense(256, activation=\"relu\")\n        # Removed the final sigmoid layer to return the feature vector instead\n\n    def call(self, inputs, training=None):\n        x = self.embedding(inputs)\n        y = self.transformer_block(x, training=training)\n        x = self.transformer_block2(x, y, y, training=training)\n        x = self.flatten(x)\n        x = self.fc1(x)\n        return self.fc2(x)\n    \n    @classmethod\n    def from_config(cls, config):\n        return cls(**config['config'])\n\nclass TransformerBlock_decode(layers.Layer):\n    def __init__(self, d_model, num_heads, ff_dim, rate=0.1):\n        super(TransformerBlock_decode, self).__init__()\n\n        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n        self.att1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n        self.ffn = keras.Sequential(\n            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(d_model)]\n        )\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n        self.dropout1 = layers.Dropout(rate)\n        self.dropout2 = layers.Dropout(rate)\n        self.dropout3 = layers.Dropout(rate)\n\n    def call(self, inputs, q, k, training=None):\n        attn_output = self.att(inputs, inputs, inputs)\n        out1 = self.layernorm1(inputs + self.dropout1(attn_output, training=training))\n\n        attn_output1 = self.att1(q, k, out1)\n        out2 = self.layernorm2(out1 + self.dropout2(attn_output1, training=training))\n\n        ffn_output = self.ffn(out2)\n        return self.layernorm3(out2 + self.dropout3(ffn_output, training=training))\n\nclass TransformerBlock_Encode(layers.Layer):\n    def __init__(self, d_model, num_heads, ff_dim, rate=0.1):\n        super(TransformerBlock_Encode, self).__init__()\n        self.con = layers.Conv1D(256, 5, padding='same')\n        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n        self.ffn = keras.Sequential(\n            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(d_model)]\n        )\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n        self.dropout1 = layers.Dropout(rate)\n        self.dropout2 = layers.Dropout(rate)\n\n    def call(self, inputs, training=None):\n        inputs = self.con(inputs)\n        attn_output = self.att(inputs, inputs, inputs)\n        out1 = self.layernorm1(inputs + self.dropout1(attn_output, training=training))\n\n        ffn_output = self.ffn(out1)\n        return self.layernorm2(out1 + self.dropout2(ffn_output, training=training))\n\n# Define the model parameters\ninput_vocab_size = data.shape[1]  # Use the actual number of features as vocab size\nd_model = 256\nnum_heads = 4\nff_dim = 128\n\nmodel = TransformerModel(input_vocab_size, d_model, num_heads, ff_dim)\n\n# Convert data to tensor\ndata_tensor = tf.convert_to_tensor(data, dtype=tf.float32)\n\n# Pass through the transformer encoder\ntransformed_features = model(data_tensor)\n\n# Save transformed features\ntransformed_features = transformed_features.numpy()\ntransformed_df = pd.DataFrame(transformed_features, columns=[f'feature_{i}' for i in range(transformed_features.shape[1])])\ntransformed_df.to_csv('transformed_data.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-07T09:04:10.072035Z","iopub.execute_input":"2024-07-07T09:04:10.072944Z","iopub.status.idle":"2024-07-07T09:04:11.424479Z","shell.execute_reply.started":"2024-07-07T09:04:10.072891Z","shell.execute_reply":"2024-07-07T09:04:11.423722Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom sklearn.preprocessing import scale\nfrom keras.saving import register_keras_serializable\n\n# Load data\npath = \"/kaggle/input/ace-dataset/auto_enco_feat/\"\ndata_ = pd.read_csv(path + 'AEDN-100.csv')\n\ndata_np = np.array(data_)\ndata = scale(data_np[:, 1:])\n\nlabel1 = np.ones((394, 1))  # Value can be changed\nlabel2 = np.zeros((626, 1))\nlabels = np.append(label1, label2)\n\n# Define the positional encoding function\ndef positional_encoding(positions, d):\n    pos = np.arange(positions)[:, np.newaxis]\n    k = np.arange(d)[np.newaxis, :]\n    i = k // 2\n    angle_rads = pos / (10000 ** (2 * i / d))\n\n    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n\n    pos_encoding = angle_rads[np.newaxis, ...]\n\n    return tf.cast(pos_encoding, dtype=tf.float32)\n\n@register_keras_serializable()\nclass TransformerModel(keras.Model):\n    def __init__(self, input_vocab_size, d_model, num_heads, ff_dim, rate=0.1, maxlen=100):\n        super(TransformerModel, self).__init__()\n\n        self.embedding = layers.Embedding(input_vocab_size, d_model)\n        self.PE = positional_encoding(maxlen, d_model)\n        self.encoder_layers = [\n            TransformerBlock_Encode(d_model, num_heads, ff_dim, rate) for _ in range(2)\n        ]\n        self.flatten = layers.Flatten()\n        self.linear = layers.Dense(1024, activation=\"relu\")\n        self.output_layer = layers.Dense(1, activation=\"sigmoid\")  # Assuming binary classification\n\n    def call(self, inputs, training=None):\n        x = self.embedding(inputs)\n        for encoder_layer in self.encoder_layers:\n            x = encoder_layer(x, training=training)\n        x = self.flatten(x)\n        x = self.linear(x)\n        return self.output_layer(x)\n    \n    @classmethod\n    def from_config(cls, config):\n        return cls(**config['config'])\n\nclass TransformerBlock_Encode(layers.Layer):\n    def __init__(self, d_model, num_heads, ff_dim, rate=0.1):\n        super(TransformerBlock_Encode, self).__init__()\n        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n        self.ffn = keras.Sequential(\n            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(d_model)]\n        )\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n        self.dropout1 = layers.Dropout(rate)\n        self.dropout2 = layers.Dropout(rate)\n\n    def call(self, inputs, training=None):\n        attn_output = self.att(inputs, inputs, inputs)\n        out1 = self.layernorm1(inputs + self.dropout1(attn_output, training=training))\n\n        ffn_output = self.ffn(out1)\n        return self.layernorm2(out1 + self.dropout2(ffn_output, training=training))\n\n# Define the model parameters\ninput_vocab_size = data.shape[1]  # Use the actual number of features as vocab size\nd_model = 256\nnum_heads = 4\nff_dim = 128\n\nmodel = TransformerModel(input_vocab_size, d_model, num_heads, ff_dim)\n\n# Convert data to tensor\ndata_tensor = tf.convert_to_tensor(data, dtype=tf.float32)\n\n# Pass through the transformer encoder\ntransformed_features = model(data_tensor)\n\n# Save transformed features\ntransformed_features = transformed_features.numpy()\ntransformed_df = pd.DataFrame(transformed_features, columns=[f'feature_{i}' for i in range(transformed_features.shape[1])])\ntransformed_df.to_csv('transformed_data2.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-07T09:08:15.096612Z","iopub.execute_input":"2024-07-07T09:08:15.097031Z","iopub.status.idle":"2024-07-07T09:08:15.823514Z","shell.execute_reply.started":"2024-07-07T09:08:15.097001Z","shell.execute_reply":"2024-07-07T09:08:15.822595Z"},"trusted":true},"execution_count":5,"outputs":[]}]}