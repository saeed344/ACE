{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f629e5de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:23:01.108590Z",
     "iopub.status.busy": "2024-05-06T18:23:01.108308Z",
     "iopub.status.idle": "2024-05-06T18:23:01.782510Z",
     "shell.execute_reply": "2024-05-06T18:23:01.781602Z"
    },
    "id": "arwnxlVCG7Dk",
    "papermill": {
     "duration": 0.688098,
     "end_time": "2024-05-06T18:23:01.785010",
     "exception": false,
     "start_time": "2024-05-06T18:23:01.096912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffc29255",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:23:01.806751Z",
     "iopub.status.busy": "2024-05-06T18:23:01.805957Z",
     "iopub.status.idle": "2024-05-06T18:23:01.809944Z",
     "shell.execute_reply": "2024-05-06T18:23:01.809158Z"
    },
    "id": "etwfoCm4FzJD",
    "outputId": "065aa862-131c-4bc9-a43c-5fb61f535fae",
    "papermill": {
     "duration": 0.016579,
     "end_time": "2024-05-06T18:23:01.811836",
     "exception": false,
     "start_time": "2024-05-06T18:23:01.795257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c29b427",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:23:01.834129Z",
     "iopub.status.busy": "2024-05-06T18:23:01.833853Z",
     "iopub.status.idle": "2024-05-06T18:23:01.867368Z",
     "shell.execute_reply": "2024-05-06T18:23:01.866698Z"
    },
    "id": "55BKZYkHGyLq",
    "papermill": {
     "duration": 0.046885,
     "end_time": "2024-05-06T18:23:01.869317",
     "exception": false,
     "start_time": "2024-05-06T18:23:01.822432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rnnamp_model = pd.read_csv('/kaggle/input/hemolytic/combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f72aaf5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:23:01.890040Z",
     "iopub.status.busy": "2024-05-06T18:23:01.889774Z",
     "iopub.status.idle": "2024-05-06T18:23:01.896908Z",
     "shell.execute_reply": "2024-05-06T18:23:01.896091Z"
    },
    "id": "xBIFhP4-HHpR",
    "papermill": {
     "duration": 0.019597,
     "end_time": "2024-05-06T18:23:01.898817",
     "exception": false,
     "start_time": "2024-05-06T18:23:01.879220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X=rnnamp_model['text']\n",
    "y=np.array(rnnamp_model['labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41b87f08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:23:01.920547Z",
     "iopub.status.busy": "2024-05-06T18:23:01.920279Z",
     "iopub.status.idle": "2024-05-06T18:23:13.327983Z",
     "shell.execute_reply": "2024-05-06T18:23:13.327149Z"
    },
    "id": "9XWOVLm3IWdM",
    "papermill": {
     "duration": 11.42165,
     "end_time": "2024-05-06T18:23:13.330220",
     "exception": false,
     "start_time": "2024-05-06T18:23:01.908570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,models\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop,SGD\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.saving import register_keras_serializable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d2417f",
   "metadata": {
    "id": "2q-aMhFDM1fe",
    "papermill": {
     "duration": 0.009638,
     "end_time": "2024-05-06T18:23:13.350133",
     "exception": false,
     "start_time": "2024-05-06T18:23:13.340495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db663f57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:23:13.371456Z",
     "iopub.status.busy": "2024-05-06T18:23:13.370960Z",
     "iopub.status.idle": "2024-05-06T18:23:13.380192Z",
     "shell.execute_reply": "2024-05-06T18:23:13.379504Z"
    },
    "id": "uv9R2gGqdiEV",
    "papermill": {
     "duration": 0.021959,
     "end_time": "2024-05-06T18:23:13.382180",
     "exception": false,
     "start_time": "2024-05-06T18:23:13.360221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b041349c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:23:13.403752Z",
     "iopub.status.busy": "2024-05-06T18:23:13.403037Z",
     "iopub.status.idle": "2024-05-06T18:23:13.409986Z",
     "shell.execute_reply": "2024-05-06T18:23:13.409215Z"
    },
    "id": "HWE99tR1ITF-",
    "outputId": "0f520fa4-bf67-4292-df5e-2efb2646541a",
    "papermill": {
     "duration": 0.019322,
     "end_time": "2024-05-06T18:23:13.411956",
     "exception": false,
     "start_time": "2024-05-06T18:23:13.392634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Example data\\ntexts = X_train\\n\\n# Tokenize the texts\\ntokenizer = Tokenizer()\\ntokenizer.fit_on_texts(texts)\\n\\n# Convert text to sequences of integers\\nsequences = tokenizer.texts_to_sequences(texts)\\ntest_seq=tokenizer.texts_to_sequences(X_test)\\n# Pad sequences to a fixed length\\nmaxlen = 100  # Adjust as needed based on your data\\npadded_sequences = pad_sequences(sequences, maxlen=maxlen, padding='post', truncating='post')\\ntest=pad_sequences(test_seq, maxlen=maxlen, padding='post', truncating='post')\\n# Convert to NumPy array\\nX_train = tf.constant(padded_sequences)\\nX_test = tf.constant(test)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Example data\n",
    "texts = X_train\n",
    "\n",
    "# Tokenize the texts\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# Convert text to sequences of integers\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "test_seq=tokenizer.texts_to_sequences(X_test)\n",
    "# Pad sequences to a fixed length\n",
    "maxlen = 100  # Adjust as needed based on your data\n",
    "padded_sequences = pad_sequences(sequences, maxlen=maxlen, padding='post', truncating='post')\n",
    "test=pad_sequences(test_seq, maxlen=maxlen, padding='post', truncating='post')\n",
    "# Convert to NumPy array\n",
    "X_train = tf.constant(padded_sequences)\n",
    "X_test = tf.constant(test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3d20d41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:23:13.432978Z",
     "iopub.status.busy": "2024-05-06T18:23:13.432675Z",
     "iopub.status.idle": "2024-05-06T18:23:13.436674Z",
     "shell.execute_reply": "2024-05-06T18:23:13.435898Z"
    },
    "id": "-QBDWhJ3zRp7",
    "papermill": {
     "duration": 0.016644,
     "end_time": "2024-05-06T18:23:13.438531",
     "exception": false,
     "start_time": "2024-05-06T18:23:13.421887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eed94e",
   "metadata": {
    "id": "KUctT5aQzjYs",
    "papermill": {
     "duration": 0.009838,
     "end_time": "2024-05-06T18:23:13.458172",
     "exception": false,
     "start_time": "2024-05-06T18:23:13.448334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a1b5c3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:23:13.479589Z",
     "iopub.status.busy": "2024-05-06T18:23:13.479318Z",
     "iopub.status.idle": "2024-05-06T18:23:15.813690Z",
     "shell.execute_reply": "2024-05-06T18:23:15.812895Z"
    },
    "id": "CssLBsIAfRtH",
    "papermill": {
     "duration": 2.347387,
     "end_time": "2024-05-06T18:23:15.816001",
     "exception": false,
     "start_time": "2024-05-06T18:23:13.468614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenizer(text,max_len):\n",
    "  #dic={'A':1,'G':1,'V':1,'I':2,'L':2,'F':2,'P':2,'Y':3,'M':3,'T':3,'S':3,'H':4,'N':4,'Q':4,'W':4,'K':5,'R':5,'D':6,'E':6,'C':7}\n",
    "  dic={'A':1,'G':2,'V':3,'I':4,'L':5,'F':6,'P':7,'Y':8,'M':9,'T':10,'S':11,'H':12,'N':13,'Q':14,'W':15,'K':16,'R':17,'D':18,'E':19,'C':20}\n",
    "  onehot=[]\n",
    "  t=[]\n",
    "  for i in range(len(text)):\n",
    "    row=[]\n",
    "    l=[]\n",
    "    char=text[i].split(' ')\n",
    "    for j in range(max_len):\n",
    "      if j< len(char):\n",
    "        row.append(dic[char[j]])\n",
    "        r=np.zeros(20)\n",
    "        r[dic[char[j]]-1]=1\n",
    "      else:\n",
    "        r=np.ones(20)*-1\n",
    "        row.append(0)\n",
    "      l.append(r)\n",
    "    l=np.array(l)\n",
    "    onehot.append(l)\n",
    "    t.append(row)\n",
    "  onehot=np.array(onehot)\n",
    "  t=np.array(t)\n",
    "  return t,onehot\n",
    "max_len=50\n",
    "X_train,onehot_train=tokenizer(X_train,max_len)\n",
    "X_test,onehot_test=tokenizer(X_test,max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55cd5c0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:23:15.848722Z",
     "iopub.status.busy": "2024-05-06T18:23:15.848165Z",
     "iopub.status.idle": "2024-05-06T18:23:15.854897Z",
     "shell.execute_reply": "2024-05-06T18:23:15.854057Z"
    },
    "id": "78cDRMz5-8j2",
    "papermill": {
     "duration": 0.022308,
     "end_time": "2024-05-06T18:23:15.856800",
     "exception": false,
     "start_time": "2024-05-06T18:23:15.834492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def positional_encoding(positions, d):\n",
    "\n",
    "    # initialize a matrix angle_rads of all the angles\n",
    "    pos=np.arange(positions)[:, np.newaxis] #Column vector containing the position span [0,1,..., positions]\n",
    "    k= np.arange(d)[np.newaxis, :]  #Row vector containing the dimension span [[0, 1, ..., d-1]]\n",
    "    i = k//2\n",
    "    angle_rads = pos/(10000**(2*i/d)) #Matrix of angles indexed by (pos,i)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    #adds batch axis\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b806d8",
   "metadata": {
    "id": "TyGqUBPEpfxg",
    "papermill": {
     "duration": 0.009983,
     "end_time": "2024-05-06T18:23:15.876979",
     "exception": false,
     "start_time": "2024-05-06T18:23:15.866996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f997c4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:23:15.898203Z",
     "iopub.status.busy": "2024-05-06T18:23:15.897955Z",
     "iopub.status.idle": "2024-05-06T18:25:01.597175Z",
     "shell.execute_reply": "2024-05-06T18:25:01.596364Z"
    },
    "id": "cXObcCXqFiGy",
    "outputId": "03866393-b8b1-43e0-e0af-80078cd004fb",
    "papermill": {
     "duration": 105.712225,
     "end_time": "2024-05-06T18:25:01.599134",
     "exception": false,
     "start_time": "2024-05-06T18:23:15.886909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "162/162 [==============================] - 17s 42ms/step - loss: 0.4707 - accuracy: 0.7759 - val_loss: 0.3767 - val_accuracy: 0.8574\n",
      "Epoch 2/100\n",
      "162/162 [==============================] - 6s 38ms/step - loss: 0.3194 - accuracy: 0.8578 - val_loss: 0.3498 - val_accuracy: 0.8609\n",
      "Epoch 3/100\n",
      "162/162 [==============================] - 6s 38ms/step - loss: 0.2574 - accuracy: 0.8913 - val_loss: 0.3510 - val_accuracy: 0.8643\n",
      "Epoch 4/100\n",
      "162/162 [==============================] - 6s 38ms/step - loss: 0.2148 - accuracy: 0.9129 - val_loss: 0.3312 - val_accuracy: 0.8748\n",
      "Epoch 5/100\n",
      "162/162 [==============================] - 6s 38ms/step - loss: 0.1772 - accuracy: 0.9307 - val_loss: 0.3245 - val_accuracy: 0.8765\n",
      "Epoch 6/100\n",
      "162/162 [==============================] - 6s 38ms/step - loss: 0.1535 - accuracy: 0.9375 - val_loss: 0.3285 - val_accuracy: 0.8817\n",
      "Epoch 7/100\n",
      "162/162 [==============================] - 6s 38ms/step - loss: 0.1282 - accuracy: 0.9499 - val_loss: 0.3610 - val_accuracy: 0.8800\n",
      "Epoch 8/100\n",
      "162/162 [==============================] - 6s 38ms/step - loss: 0.1038 - accuracy: 0.9627 - val_loss: 0.3830 - val_accuracy: 0.8748\n",
      "Epoch 9/100\n",
      "162/162 [==============================] - 6s 39ms/step - loss: 0.0983 - accuracy: 0.9623 - val_loss: 0.3289 - val_accuracy: 0.8957\n",
      "Epoch 10/100\n",
      "162/162 [==============================] - 6s 39ms/step - loss: 0.0846 - accuracy: 0.9700 - val_loss: 0.3512 - val_accuracy: 0.8887\n",
      "Epoch 11/100\n",
      "162/162 [==============================] - 6s 39ms/step - loss: 0.0701 - accuracy: 0.9754 - val_loss: 0.3748 - val_accuracy: 0.8870\n",
      "Epoch 12/100\n",
      "162/162 [==============================] - 6s 39ms/step - loss: 0.0687 - accuracy: 0.9750 - val_loss: 0.4329 - val_accuracy: 0.8835\n",
      "Epoch 13/100\n",
      "162/162 [==============================] - 6s 40ms/step - loss: 0.0660 - accuracy: 0.9776 - val_loss: 0.4093 - val_accuracy: 0.8817\n",
      "Epoch 14/100\n",
      "162/162 [==============================] - 6s 40ms/step - loss: 0.0576 - accuracy: 0.9781 - val_loss: 0.4459 - val_accuracy: 0.9026\n",
      "Epoch 15/100\n",
      "162/162 [==============================] - 6s 39ms/step - loss: 0.0541 - accuracy: 0.9799 - val_loss: 0.4141 - val_accuracy: 0.8957\n"
     ]
    }
   ],
   "source": [
    "@register_keras_serializable()\n",
    "class TransformerModel(keras.Model):\n",
    "    def __init__(self, input_vocab_size, d_model, num_heads, ff_dim, rate=0.1, maxlen=50):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.embedding = layers.Embedding(input_vocab_size, d_model)\n",
    "        self.PE = positional_encoding(maxlen, d_model)\n",
    "        self.transformer_block = TransformerBlock_Encode(d_model, num_heads, ff_dim, rate)\n",
    "        self.transformer_block2 = TransformerBlock_decode(d_model, num_heads, ff_dim, rate)\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc1 = layers.Dense(512, activation=\"relu\")\n",
    "        self.fc3 = layers.Dense(256, activation=\"relu\")\n",
    "        self.fc2 = layers.Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        x = self.embedding(inputs)\n",
    "        #x = x+self.PE\n",
    "        y = self.transformer_block(x)\n",
    "        x = self.transformer_block2(x,y,y)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc3(x)\n",
    "        return self.fc2(x)\n",
    "class TransformerBlock_decode(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock_decode, self).__init__()\n",
    "\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.att1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(d_model)]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "        self.dropout3 = layers.Dropout(rate)\n",
    "    def call(self, inputs,q,k, training):\n",
    "        attn_output = self.att(inputs, inputs,inputs)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        attn_output1=self.att(q, k,out1)\n",
    "        out2 = self.layernorm1(out1 + attn_output1)\n",
    "        ffn_output = self.ffn(out2)\n",
    "        return self.layernorm2(out2 + ffn_output)\n",
    "\n",
    "# Define the TransformerBlock layer\n",
    "class TransformerBlock_Encode(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock_Encode, self).__init__()\n",
    "        self.con= layers.Conv1D(256,5,padding='same')\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(d_model)]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        inputs=self.con(inputs)\n",
    "        attn_output = self.att(inputs, inputs,inputs)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "\n",
    "# Define your data loading and preprocessing here\n",
    "# Example: X_train, y_train = load_data_and_preprocess()\n",
    "\n",
    "# Define the model\n",
    "input_vocab_size = 1024  # Replace with the actual vocabulary size\n",
    "d_model = 256\n",
    "num_heads = 8\n",
    "ff_dim = 256\n",
    "\n",
    "model = TransformerModel(input_vocab_size, d_model, num_heads, ff_dim)\n",
    "initial_learning_rate = 0.0001\n",
    "optimizer = Adam(learning_rate=initial_learning_rate)\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), metrics=[\"accuracy\"])\n",
    "\n",
    "callback = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10),tf.keras.callbacks.ModelCheckpoint(filepath='AMAP1.h5', monitor='val_accuracy', save_best_only=True,mode='auto',save_weights_only=True)]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train,y_train,epochs = 100,batch_size=32,validation_split=0.1,callbacks=[callback],verbose=1,shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed34794c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:25:01.817161Z",
     "iopub.status.busy": "2024-05-06T18:25:01.816824Z",
     "iopub.status.idle": "2024-05-06T18:25:02.324525Z",
     "shell.execute_reply": "2024-05-06T18:25:02.323767Z"
    },
    "id": "Bm5Vdbe-lVeT",
    "papermill": {
     "duration": 0.618761,
     "end_time": "2024-05-06T18:25:02.326867",
     "exception": false,
     "start_time": "2024-05-06T18:25:01.708106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_weights('/kaggle/input/amap/tensorflow2/model/1/AMAP1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9de673a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:25:02.542055Z",
     "iopub.status.busy": "2024-05-06T18:25:02.541698Z",
     "iopub.status.idle": "2024-05-06T18:25:02.545632Z",
     "shell.execute_reply": "2024-05-06T18:25:02.544786Z"
    },
    "id": "xHT6ycII_PcZ",
    "papermill": {
     "duration": 0.112166,
     "end_time": "2024-05-06T18:25:02.547468",
     "exception": false,
     "start_time": "2024-05-06T18:25:02.435302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1=model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29483c80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:25:02.761736Z",
     "iopub.status.busy": "2024-05-06T18:25:02.761423Z",
     "iopub.status.idle": "2024-05-06T18:25:46.771193Z",
     "shell.execute_reply": "2024-05-06T18:25:46.770215Z"
    },
    "id": "Ep5tIGliLqWA",
    "outputId": "a2379bb7-f2ff-455a-f8ec-d3c0f7c51fba",
    "papermill": {
     "duration": 44.119755,
     "end_time": "2024-05-06T18:25:46.773187",
     "exception": false,
     "start_time": "2024-05-06T18:25:02.653432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 3s 14ms/step\n",
      "combined train datasets\n",
      "deep learning: Accuracy 97.54%\n",
      "deep learning: Precision-Recall 95.46%\n",
      "deep learning: Matthews Coefficient 94.96%\n",
      "deep learning: Cohen Kappa Score 94.96%\n",
      "deep learning: F1-Score 97.08%\n",
      "deep learning: AUC Score 99.46%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       low 0       0.98      0.98      0.98      3332\n",
      "      high 1       0.97      0.97      0.97      2411\n",
      "\n",
      "    accuracy                           0.98      5743\n",
      "   macro avg       0.97      0.97      0.97      5743\n",
      "weighted avg       0.98      0.98      0.98      5743\n",
      "\n",
      "combined test datasets\n",
      "45/45 [==============================] - 1s 14ms/step\n",
      "deep learning: Accuracy 89.28%\n",
      "deep learning: Precision 87.59%\n",
      "deep learning: Recall 86.41%\n",
      "deep learning: Matthews Coefficient 77.88%\n",
      "deep learning: Cohen Kappa Score 77.87%\n",
      "deep learning: F1-Score 86.99%\n",
      "deep learning: AUC Score 94.23%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       low 0       0.90      0.91      0.91       840\n",
      "      high 1       0.88      0.86      0.87       596\n",
      "\n",
      "    accuracy                           0.89      1436\n",
      "   macro avg       0.89      0.89      0.89      1436\n",
      "weighted avg       0.89      0.89      0.89      1436\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, metrics\n",
    "y_pred=model.predict(X_train)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_train, y_pred, pos_label=1)\n",
    "auc=metrics.auc(fpr, tpr)\n",
    "\n",
    "y_pred[y_pred>0.5]=1\n",
    "y_pred[y_pred<0.5]=0\n",
    "\n",
    "cv_preds = y_pred\n",
    "print('combined train datasets')\n",
    "name='deep learning'\n",
    "print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_train, cv_preds)))\n",
    "print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_train, cv_preds)))\n",
    "print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*metrics.matthews_corrcoef(y_train, cv_preds)))\n",
    "print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_train, cv_preds)))\n",
    "print(\"%s: F1-Score %0.2f%%\" % (name, 100*metrics.f1_score(y_train, cv_preds)))\n",
    "print(\"%s: AUC Score %0.2f%%\" % (name, 100*auc))\n",
    "target_names = ['low 0', 'high 1']\n",
    "print(metrics.classification_report(y_train, cv_preds, target_names=target_names))\n",
    "\n",
    "# Predictions Validation Set\n",
    "print('combined test datasets')\n",
    "y_pred2=model.predict(X_test)\n",
    "l=np.zeros(len(y_pred2))\n",
    "l=l.reshape(-1,1)\n",
    "l[y_pred2>=0.5]=1\n",
    "l[y_pred2<0.5]=0\n",
    "cv_preds2 = l\n",
    "print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_test, cv_preds2)))\n",
    "print(\"%s: Precision %0.2f%%\" % (name, 100*metrics.precision_score(y_test, cv_preds2)))\n",
    "print(\"%s: Recall %0.2f%%\" % (name, 100*metrics.recall_score(y_test, cv_preds2)))\n",
    "print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*metrics.matthews_corrcoef(y_test, cv_preds2)))\n",
    "print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_test, cv_preds2)))\n",
    "print(\"%s: F1-Score %0.2f%%\" % (name, 100*metrics.f1_score(y_test, cv_preds2)))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred2, pos_label=1)\n",
    "auc=metrics.auc(fpr, tpr)\n",
    "print(\"%s: AUC Score %0.2f%%\" % (name, 100*auc))\n",
    "\n",
    "target_names = ['low 0', 'high 1']\n",
    "print(metrics.classification_report(y_test, cv_preds2, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0faafa33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:25:46.998169Z",
     "iopub.status.busy": "2024-05-06T18:25:46.997676Z",
     "iopub.status.idle": "2024-05-06T18:25:47.027832Z",
     "shell.execute_reply": "2024-05-06T18:25:47.026904Z"
    },
    "id": "qs4nHEvx-SI3",
    "papermill": {
     "duration": 0.144347,
     "end_time": "2024-05-06T18:25:47.029869",
     "exception": false,
     "start_time": "2024-05-06T18:25:46.885522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rnnamp_model = pd.read_csv('/kaggle/input/hemolytic/hlppredfuse.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abd6a2bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:25:47.255454Z",
     "iopub.status.busy": "2024-05-06T18:25:47.255153Z",
     "iopub.status.idle": "2024-05-06T18:25:47.260443Z",
     "shell.execute_reply": "2024-05-06T18:25:47.259497Z"
    },
    "id": "XlB6biA8-SI-",
    "papermill": {
     "duration": 0.121013,
     "end_time": "2024-05-06T18:25:47.262386",
     "exception": false,
     "start_time": "2024-05-06T18:25:47.141373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X=rnnamp_model['text']\n",
    "y=np.array(rnnamp_model['labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9beb6db7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:25:47.488329Z",
     "iopub.status.busy": "2024-05-06T18:25:47.487333Z",
     "iopub.status.idle": "2024-05-06T18:25:47.493955Z",
     "shell.execute_reply": "2024-05-06T18:25:47.493159Z"
    },
    "id": "f5fFAg1x-SI-",
    "papermill": {
     "duration": 0.121061,
     "end_time": "2024-05-06T18:25:47.496045",
     "exception": false,
     "start_time": "2024-05-06T18:25:47.374984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4c74e72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:25:47.718855Z",
     "iopub.status.busy": "2024-05-06T18:25:47.718526Z",
     "iopub.status.idle": "2024-05-06T18:25:47.722981Z",
     "shell.execute_reply": "2024-05-06T18:25:47.722076Z"
    },
    "id": "_0LgRfEY-SI_",
    "papermill": {
     "duration": 0.118426,
     "end_time": "2024-05-06T18:25:47.725072",
     "exception": false,
     "start_time": "2024-05-06T18:25:47.606646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2800da46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:25:47.950370Z",
     "iopub.status.busy": "2024-05-06T18:25:47.950083Z",
     "iopub.status.idle": "2024-05-06T18:25:48.900223Z",
     "shell.execute_reply": "2024-05-06T18:25:48.899142Z"
    },
    "id": "kTXGBr65-SI_",
    "papermill": {
     "duration": 1.064917,
     "end_time": "2024-05-06T18:25:48.902604",
     "exception": false,
     "start_time": "2024-05-06T18:25:47.837687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenizer(text,max_len):\n",
    "  #dic={'A':1,'G':1,'V':1,'I':2,'L':2,'F':2,'P':2,'Y':3,'M':3,'T':3,'S':3,'H':4,'N':4,'Q':4,'W':4,'K':5,'R':5,'D':6,'E':6,'C':7}\n",
    "  dic={'A':1,'G':2,'V':3,'I':4,'L':5,'F':6,'P':7,'Y':8,'M':9,'T':10,'S':11,'H':12,'N':13,'Q':14,'W':15,'K':16,'R':17,'D':18,'E':19,'C':20}\n",
    "  onehot=[]\n",
    "  t=[]\n",
    "  for i in range(len(text)):\n",
    "    row=[]\n",
    "    l=[]\n",
    "    char=text[i].split(' ')\n",
    "    for j in range(max_len):\n",
    "      if j< len(char):\n",
    "        row.append(dic[char[j]])\n",
    "        r=np.zeros(20)\n",
    "        r[dic[char[j]]-1]=1\n",
    "      else:\n",
    "        r=np.ones(20)*-1\n",
    "        row.append(0)\n",
    "      l.append(r)\n",
    "    l=np.array(l)\n",
    "    onehot.append(l)\n",
    "    t.append(row)\n",
    "  onehot=np.array(onehot)\n",
    "  t=np.array(t)\n",
    "  return t,onehot\n",
    "max_len=50\n",
    "X_train,onehot_train=tokenizer(X_train,max_len)\n",
    "X_test,onehot_test=tokenizer(X_test,max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2b94697",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:25:49.146909Z",
     "iopub.status.busy": "2024-05-06T18:25:49.145961Z",
     "iopub.status.idle": "2024-05-06T18:26:52.580209Z",
     "shell.execute_reply": "2024-05-06T18:26:52.579108Z"
    },
    "id": "4o7zagCK7eRH",
    "outputId": "6a276bf5-38a8-4d50-e9fa-e814e185bfd6",
    "papermill": {
     "duration": 63.565816,
     "end_time": "2024-05-06T18:26:52.583146",
     "exception": false,
     "start_time": "2024-05-06T18:25:49.017330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80/80 [==============================] - 12s 52ms/step - loss: 0.3332 - accuracy: 0.8693 - val_loss: 0.1700 - val_accuracy: 0.9397\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 3s 40ms/step - loss: 0.1436 - accuracy: 0.9463 - val_loss: 0.2534 - val_accuracy: 0.9007\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.1292 - accuracy: 0.9534 - val_loss: 0.1774 - val_accuracy: 0.9397\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.0899 - accuracy: 0.9668 - val_loss: 0.1650 - val_accuracy: 0.9326\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.0575 - accuracy: 0.9834 - val_loss: 0.1796 - val_accuracy: 0.9433\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 3s 40ms/step - loss: 0.0418 - accuracy: 0.9870 - val_loss: 0.1578 - val_accuracy: 0.9433\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 3s 40ms/step - loss: 0.0311 - accuracy: 0.9913 - val_loss: 0.1570 - val_accuracy: 0.9433\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 0.0177 - accuracy: 0.9957 - val_loss: 0.2028 - val_accuracy: 0.9433\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 0.0120 - accuracy: 0.9972 - val_loss: 0.1810 - val_accuracy: 0.9539\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 3s 40ms/step - loss: 0.0085 - accuracy: 0.9984 - val_loss: 0.2038 - val_accuracy: 0.9504\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 3s 40ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9539\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2345 - val_accuracy: 0.9433\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.9433\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9539\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9539\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 6.8220e-04 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9504\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 5.1817e-04 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.9504\n"
     ]
    }
   ],
   "source": [
    "@register_keras_serializable()\n",
    "class TransformerModel(keras.Model):\n",
    "    def __init__(self, input_vocab_size, d_model, num_heads, ff_dim, rate=0.1, maxlen=50):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.embedding = layers.Embedding(input_vocab_size, d_model)\n",
    "        self.PE = positional_encoding(maxlen, d_model)\n",
    "        self.transformer_block = TransformerBlock_Encode(d_model, num_heads, ff_dim, rate)\n",
    "        self.transformer_block2 = TransformerBlock_decode(d_model, num_heads, ff_dim, rate)\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc1 = layers.Dense(512, activation=\"relu\")\n",
    "        self.fc3 = layers.Dense(256, activation=\"relu\")\n",
    "        self.fc2 = layers.Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        x = self.embedding(inputs)\n",
    "        #x = x+self.PE\n",
    "        y = self.transformer_block(x)\n",
    "        x = self.transformer_block2(x,y,y)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc3(x)\n",
    "        return self.fc2(x)\n",
    "class TransformerBlock_decode(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock_decode, self).__init__()\n",
    "\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.att1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(d_model)]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "        self.dropout3 = layers.Dropout(rate)\n",
    "    def call(self, inputs,q,k, training):\n",
    "        attn_output = self.att(inputs, inputs,inputs)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        attn_output1=self.att(q, k,out1)\n",
    "        out2 = self.layernorm1(out1 + attn_output1)\n",
    "        ffn_output = self.ffn(out2)\n",
    "        return self.layernorm2(out2 + ffn_output)\n",
    "\n",
    "# Define the TransformerBlock layer\n",
    "class TransformerBlock_Encode(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock_Encode, self).__init__()\n",
    "        self.con= layers.Conv1D(256,5,padding='same')\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(d_model)]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        inputs=self.con(inputs)\n",
    "        attn_output = self.att(inputs, inputs,inputs)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "\n",
    "# Define your data loading and preprocessing here\n",
    "# Example: X_train, y_train = load_data_and_preprocess()\n",
    "\n",
    "# Define the model\n",
    "input_vocab_size = 1024  # Replace with the actual vocabulary size\n",
    "d_model = 256\n",
    "num_heads = 8\n",
    "ff_dim = 256\n",
    "model2 = TransformerModel(input_vocab_size, d_model, num_heads, ff_dim)\n",
    "initial_learning_rate = 0.0001\n",
    "optimizer = Adam(learning_rate=initial_learning_rate)\n",
    "# Compile the model\n",
    "model2.compile(optimizer=optimizer, loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), metrics=[\"accuracy\"])\n",
    "\n",
    "callback = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10),tf.keras.callbacks.ModelCheckpoint(filepath='AMAP2.h5', monitor='val_accuracy', save_best_only=True,mode='auto',save_weights_only=True)]\n",
    "\n",
    "# Train the model\n",
    "history = model2.fit(X_train,y_train,epochs = 100,batch_size=32,validation_split=0.1,callbacks=[callback],verbose=1,shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44e9db02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:26:52.968667Z",
     "iopub.status.busy": "2024-05-06T18:26:52.967922Z",
     "iopub.status.idle": "2024-05-06T18:26:53.543899Z",
     "shell.execute_reply": "2024-05-06T18:26:53.543042Z"
    },
    "id": "oxPvpG1Z7m2v",
    "papermill": {
     "duration": 0.754903,
     "end_time": "2024-05-06T18:26:53.546290",
     "exception": false,
     "start_time": "2024-05-06T18:26:52.791387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2.load_weights('/kaggle/input/amap/tensorflow2/model/1/AMAP2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f3e01b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:26:53.892016Z",
     "iopub.status.busy": "2024-05-06T18:26:53.891299Z",
     "iopub.status.idle": "2024-05-06T18:26:54.011979Z",
     "shell.execute_reply": "2024-05-06T18:26:54.010870Z"
    },
    "id": "k9NxcbR5Lh4f",
    "papermill": {
     "duration": 0.296869,
     "end_time": "2024-05-06T18:26:54.015624",
     "exception": false,
     "start_time": "2024-05-06T18:26:53.718755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2.save_weights(\"AMAP2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cc2cd59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:26:54.376783Z",
     "iopub.status.busy": "2024-05-06T18:26:54.376057Z",
     "iopub.status.idle": "2024-05-06T18:27:17.203889Z",
     "shell.execute_reply": "2024-05-06T18:27:17.202681Z"
    },
    "id": "x71T_rAI7m2v",
    "outputId": "f5cf2956-e0fe-4936-dfdc-ec892cacb6d3",
    "papermill": {
     "duration": 23.003277,
     "end_time": "2024-05-06T18:27:17.206062",
     "exception": false,
     "start_time": "2024-05-06T18:26:54.202785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 2s 14ms/step\n",
      "hlppredfuse train datasets\n",
      "deep learning: Accuracy 99.29%\n",
      "deep learning: Precision-Recall 98.29%\n",
      "deep learning: Matthews Coefficient 98.34%\n",
      "deep learning: Cohen Kappa Score 98.34%\n",
      "deep learning: F1-Score 98.85%\n",
      "deep learning: AUC Score 94.23%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       low 0       0.99      1.00      0.99      1938\n",
      "      high 1       1.00      0.98      0.99       876\n",
      "\n",
      "    accuracy                           0.99      2814\n",
      "   macro avg       0.99      0.99      0.99      2814\n",
      "weighted avg       0.99      0.99      0.99      2814\n",
      "\n",
      "hlppredfuse test datasets\n",
      "22/22 [==============================] - 0s 13ms/step\n",
      "deep learning: Accuracy 96.16%\n",
      "deep learning: Precision 93.27%\n",
      "deep learning: Recall 94.55%\n",
      "deep learning: Matthews Coefficient 91.11%\n",
      "deep learning: Cohen Kappa Score 91.11%\n",
      "deep learning: F1-Score 93.91%\n",
      "deep learning: AUC Score 97.64%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       low 0       0.98      0.97      0.97       484\n",
      "      high 1       0.93      0.95      0.94       220\n",
      "\n",
      "    accuracy                           0.96       704\n",
      "   macro avg       0.95      0.96      0.96       704\n",
      "weighted avg       0.96      0.96      0.96       704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, metrics\n",
    "y_pred=model2.predict(X_train)\n",
    "y_pred[y_pred>0.5]=1\n",
    "y_pred[y_pred<0.5]=0\n",
    "\n",
    "cv_preds = y_pred\n",
    "print('hlppredfuse train datasets')\n",
    "name='deep learning'\n",
    "print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_train, cv_preds)))\n",
    "print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_train, cv_preds)))\n",
    "print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*metrics.matthews_corrcoef(y_train, cv_preds)))\n",
    "print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_train, cv_preds)))\n",
    "print(\"%s: F1-Score %0.2f%%\" % (name, 100*metrics.f1_score(y_train, cv_preds)))\n",
    "print(\"%s: AUC Score %0.2f%%\" % (name, 100*auc))\n",
    "target_names = ['low 0', 'high 1']\n",
    "print(metrics.classification_report(y_train, cv_preds, target_names=target_names))\n",
    "\n",
    "# Predictions Validation Set\n",
    "print('hlppredfuse test datasets')\n",
    "y_pred2=model2.predict(X_test)\n",
    "l=np.zeros(len(y_pred2))\n",
    "l=l.reshape(-1,1)\n",
    "l[y_pred2>=0.5]=1\n",
    "l[y_pred2<0.5]=0\n",
    "cv_preds2 = l\n",
    "print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_test, cv_preds2)))\n",
    "print(\"%s: Precision %0.2f%%\" % (name, 100*metrics.precision_score(y_test, cv_preds2)))\n",
    "print(\"%s: Recall %0.2f%%\" % (name, 100*metrics.recall_score(y_test, cv_preds2)))\n",
    "print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*metrics.matthews_corrcoef(y_test, cv_preds2)))\n",
    "print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_test, cv_preds2)))\n",
    "print(\"%s: F1-Score %0.2f%%\" % (name, 100*metrics.f1_score(y_test, cv_preds2)))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred2, pos_label=1)\n",
    "auc=metrics.auc(fpr, tpr)\n",
    "print(\"%s: AUC Score %0.2f%%\" % (name, 100*auc))\n",
    "\n",
    "target_names = ['low 0', 'high 1']\n",
    "print(metrics.classification_report(y_test, cv_preds2, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34a565c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:27:17.585896Z",
     "iopub.status.busy": "2024-05-06T18:27:17.585030Z",
     "iopub.status.idle": "2024-05-06T18:27:17.612052Z",
     "shell.execute_reply": "2024-05-06T18:27:17.611162Z"
    },
    "id": "7kJr65zb-WtS",
    "papermill": {
     "duration": 0.209258,
     "end_time": "2024-05-06T18:27:17.614019",
     "exception": false,
     "start_time": "2024-05-06T18:27:17.404761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rnnamp_model = pd.read_csv('/kaggle/input/hemolytic/rnnamp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8de1850",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:27:17.956824Z",
     "iopub.status.busy": "2024-05-06T18:27:17.956221Z",
     "iopub.status.idle": "2024-05-06T18:27:17.961172Z",
     "shell.execute_reply": "2024-05-06T18:27:17.960243Z"
    },
    "id": "WCgqgMiP-WtS",
    "papermill": {
     "duration": 0.180557,
     "end_time": "2024-05-06T18:27:17.963246",
     "exception": false,
     "start_time": "2024-05-06T18:27:17.782689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X=rnnamp_model['text']\n",
    "y=np.array(rnnamp_model['labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4aff0f15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:27:18.304422Z",
     "iopub.status.busy": "2024-05-06T18:27:18.304129Z",
     "iopub.status.idle": "2024-05-06T18:27:18.310508Z",
     "shell.execute_reply": "2024-05-06T18:27:18.309615Z"
    },
    "id": "ia1ZGn2t-WtT",
    "papermill": {
     "duration": 0.176323,
     "end_time": "2024-05-06T18:27:18.312443",
     "exception": false,
     "start_time": "2024-05-06T18:27:18.136120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b09c4042",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:27:18.664049Z",
     "iopub.status.busy": "2024-05-06T18:27:18.663697Z",
     "iopub.status.idle": "2024-05-06T18:27:18.668354Z",
     "shell.execute_reply": "2024-05-06T18:27:18.667567Z"
    },
    "id": "ZTPCKy2d-WtT",
    "papermill": {
     "duration": 0.179343,
     "end_time": "2024-05-06T18:27:18.670217",
     "exception": false,
     "start_time": "2024-05-06T18:27:18.490874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab267f8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:27:19.011426Z",
     "iopub.status.busy": "2024-05-06T18:27:19.011085Z",
     "iopub.status.idle": "2024-05-06T18:27:19.716018Z",
     "shell.execute_reply": "2024-05-06T18:27:19.715223Z"
    },
    "id": "LfLheYBz-WtT",
    "papermill": {
     "duration": 0.877095,
     "end_time": "2024-05-06T18:27:19.718143",
     "exception": false,
     "start_time": "2024-05-06T18:27:18.841048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenizer(text,max_len):\n",
    "  #dic={'A':1,'G':1,'V':1,'I':2,'L':2,'F':2,'P':2,'Y':3,'M':3,'T':3,'S':3,'H':4,'N':4,'Q':4,'W':4,'K':5,'R':5,'D':6,'E':6,'C':7}\n",
    "  dic={'A':1,'G':2,'V':3,'I':4,'L':5,'F':6,'P':7,'Y':8,'M':9,'T':10,'S':11,'H':12,'N':13,'Q':14,'W':15,'K':16,'R':17,'D':18,'E':19,'C':20}\n",
    "  onehot=[]\n",
    "  t=[]\n",
    "  for i in range(len(text)):\n",
    "    row=[]\n",
    "    l=[]\n",
    "    char=text[i].split(' ')\n",
    "    for j in range(max_len):\n",
    "      if j< len(char):\n",
    "        row.append(dic[char[j]])\n",
    "        r=np.zeros(20)\n",
    "        r[dic[char[j]]-1]=1\n",
    "      else:\n",
    "        r=np.ones(20)*-1\n",
    "        row.append(0)\n",
    "      l.append(r)\n",
    "    l=np.array(l)\n",
    "    onehot.append(l)\n",
    "    t.append(row)\n",
    "  onehot=np.array(onehot)\n",
    "  t=np.array(t)\n",
    "  return t,onehot\n",
    "max_len=50\n",
    "X_train,onehot_train=tokenizer(X_train,max_len)\n",
    "X_test,onehot_test=tokenizer(X_test,max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb854f39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:27:20.062634Z",
     "iopub.status.busy": "2024-05-06T18:27:20.062247Z",
     "iopub.status.idle": "2024-05-06T18:28:05.904525Z",
     "shell.execute_reply": "2024-05-06T18:28:05.903572Z"
    },
    "id": "wW0hCzH7-tEN",
    "outputId": "ece7fe92-0345-42bd-e68f-6682a7e7d5d8",
    "papermill": {
     "duration": 46.015792,
     "end_time": "2024-05-06T18:28:05.906607",
     "exception": false,
     "start_time": "2024-05-06T18:27:19.890815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "58/58 [==============================] - 11s 53ms/step - loss: 0.6422 - accuracy: 0.6679 - val_loss: 0.5675 - val_accuracy: 0.7073\n",
      "Epoch 2/100\n",
      "58/58 [==============================] - 2s 38ms/step - loss: 0.4797 - accuracy: 0.7745 - val_loss: 0.5685 - val_accuracy: 0.7073\n",
      "Epoch 3/100\n",
      "58/58 [==============================] - 2s 38ms/step - loss: 0.4231 - accuracy: 0.8120 - val_loss: 0.5962 - val_accuracy: 0.7073\n",
      "Epoch 4/100\n",
      "58/58 [==============================] - 2s 41ms/step - loss: 0.3699 - accuracy: 0.8462 - val_loss: 0.5294 - val_accuracy: 0.7415\n",
      "Epoch 5/100\n",
      "58/58 [==============================] - 2s 39ms/step - loss: 0.3308 - accuracy: 0.8652 - val_loss: 0.5388 - val_accuracy: 0.7366\n",
      "Epoch 6/100\n",
      "58/58 [==============================] - 3s 43ms/step - loss: 0.2992 - accuracy: 0.8707 - val_loss: 0.4772 - val_accuracy: 0.7756\n",
      "Epoch 7/100\n",
      "58/58 [==============================] - 2s 39ms/step - loss: 0.2451 - accuracy: 0.9000 - val_loss: 0.5342 - val_accuracy: 0.7512\n",
      "Epoch 8/100\n",
      "58/58 [==============================] - 2s 41ms/step - loss: 0.2327 - accuracy: 0.9038 - val_loss: 0.5922 - val_accuracy: 0.7659\n",
      "Epoch 9/100\n",
      "58/58 [==============================] - 2s 42ms/step - loss: 0.2058 - accuracy: 0.9217 - val_loss: 0.4846 - val_accuracy: 0.8098\n",
      "Epoch 10/100\n",
      "58/58 [==============================] - 2s 40ms/step - loss: 0.1790 - accuracy: 0.9359 - val_loss: 0.5114 - val_accuracy: 0.7854\n",
      "Epoch 11/100\n",
      "58/58 [==============================] - 2s 40ms/step - loss: 0.1635 - accuracy: 0.9402 - val_loss: 0.5563 - val_accuracy: 0.7951\n",
      "Epoch 12/100\n",
      "58/58 [==============================] - 2s 40ms/step - loss: 0.1368 - accuracy: 0.9505 - val_loss: 0.5875 - val_accuracy: 0.7805\n",
      "Epoch 13/100\n",
      "58/58 [==============================] - 2s 42ms/step - loss: 0.1205 - accuracy: 0.9603 - val_loss: 0.5254 - val_accuracy: 0.8146\n",
      "Epoch 14/100\n",
      "58/58 [==============================] - 2s 40ms/step - loss: 0.1086 - accuracy: 0.9652 - val_loss: 0.6051 - val_accuracy: 0.7659\n",
      "Epoch 15/100\n",
      "58/58 [==============================] - 2s 40ms/step - loss: 0.1009 - accuracy: 0.9674 - val_loss: 0.6010 - val_accuracy: 0.8098\n",
      "Epoch 16/100\n",
      "58/58 [==============================] - 2s 40ms/step - loss: 0.0872 - accuracy: 0.9663 - val_loss: 0.5934 - val_accuracy: 0.8049\n"
     ]
    }
   ],
   "source": [
    "# Define the Transformer model\n",
    "@register_keras_serializable()\n",
    "class TransformerModel(keras.Model):\n",
    "    def __init__(self, input_vocab_size, d_model, num_heads, ff_dim, rate=0.1, maxlen=50):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.embedding = layers.Embedding(input_vocab_size, d_model)\n",
    "        self.PE = positional_encoding(maxlen, d_model)\n",
    "        self.transformer_block = TransformerBlock_Encode(d_model, num_heads, ff_dim, rate)\n",
    "        self.transformer_block2 = TransformerBlock_decode(d_model, num_heads, ff_dim, rate)\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc1 = layers.Dense(512, activation=\"relu\")\n",
    "        self.fc3 = layers.Dense(256, activation=\"relu\")\n",
    "        self.fc2 = layers.Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        x = self.embedding(inputs)\n",
    "        #x = x+self.PE\n",
    "        y = self.transformer_block(x)\n",
    "        x = self.transformer_block2(x,y,y)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc3(x)\n",
    "        return self.fc2(x)\n",
    "class TransformerBlock_decode(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock_decode, self).__init__()\n",
    "\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.att1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(d_model)]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "        self.dropout3 = layers.Dropout(rate)\n",
    "    def call(self, inputs,q,k, training):\n",
    "        attn_output = self.att(inputs, inputs,inputs)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        attn_output1=self.att(q, k,out1)\n",
    "        out2 = self.layernorm1(out1 + attn_output1)\n",
    "        ffn_output = self.ffn(out2)\n",
    "        return self.layernorm2(out2 + ffn_output)\n",
    "\n",
    "# Define the TransformerBlock layer\n",
    "class TransformerBlock_Encode(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock_Encode, self).__init__()\n",
    "        self.con= layers.Conv1D(256,5,padding='same')\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(d_model)]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-1)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        inputs=self.con(inputs)\n",
    "        attn_output = self.att(inputs, inputs,inputs)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "\n",
    "# Define your data loading and preprocessing here\n",
    "# Example: X_train, y_train = load_data_and_preprocess()\n",
    "\n",
    "# Define the model\n",
    "input_vocab_size = 1024  # Replace with the actual vocabulary size\n",
    "d_model = 256\n",
    "num_heads = 8\n",
    "ff_dim = 256\n",
    "model3 = TransformerModel(input_vocab_size, d_model, num_heads, ff_dim)\n",
    "initial_learning_rate = 0.0001\n",
    "optimizer = Adam(learning_rate=initial_learning_rate)\n",
    "# Compile the model\n",
    "model3.compile(optimizer=optimizer, loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), metrics=[\"accuracy\"])\n",
    "callback = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10),tf.keras.callbacks.ModelCheckpoint(filepath='AMAP3.h5', monitor='val_accuracy', save_best_only=True,mode='auto',save_weights_only=True)]\n",
    "\n",
    "# Train the model\n",
    "history = model3.fit(X_train,y_train,epochs = 100,batch_size=32,validation_split=0.1,callbacks=[callback],verbose=1,shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6266333a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:28:06.379118Z",
     "iopub.status.busy": "2024-05-06T18:28:06.378709Z",
     "iopub.status.idle": "2024-05-06T18:28:06.875309Z",
     "shell.execute_reply": "2024-05-06T18:28:06.874426Z"
    },
    "id": "_hKa8EZ9-tEU",
    "papermill": {
     "duration": 0.709627,
     "end_time": "2024-05-06T18:28:06.877794",
     "exception": false,
     "start_time": "2024-05-06T18:28:06.168167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model3.load_weights('/kaggle/input/amap/tensorflow2/model/1/AMAP3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6fbe6295",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:28:07.306107Z",
     "iopub.status.busy": "2024-05-06T18:28:07.305716Z",
     "iopub.status.idle": "2024-05-06T18:28:09.124482Z",
     "shell.execute_reply": "2024-05-06T18:28:09.123232Z"
    },
    "id": "ZBAhB9ww-tEV",
    "papermill": {
     "duration": 2.030766,
     "end_time": "2024-05-06T18:28:09.126500",
     "exception": false,
     "start_time": "2024-05-06T18:28:07.095734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 16ms/step\n",
      "rnnamp train datasets\n",
      "deep learning: Accuracy 94.96%\n",
      "deep learning: Precision-Recall 93.30%\n",
      "deep learning: Matthews Coefficient 89.88%\n",
      "deep learning: Cohen Kappa Score 89.88%\n",
      "deep learning: F1-Score 95.29%\n",
      "deep learning: AUC Score 97.64%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       low 0       0.95      0.95      0.95       952\n",
      "      high 1       0.95      0.95      0.95      1093\n",
      "\n",
      "    accuracy                           0.95      2045\n",
      "   macro avg       0.95      0.95      0.95      2045\n",
      "weighted avg       0.95      0.95      0.95      2045\n",
      "\n",
      "rnnamp test datasets\n",
      "16/16 [==============================] - 0s 13ms/step\n",
      "deep learning: Accuracy 79.69%\n",
      "deep learning: Precision 82.93%\n",
      "deep learning: Recall 76.69%\n",
      "deep learning: Matthews Coefficient 59.62%\n",
      "deep learning: Cohen Kappa Score 59.44%\n",
      "deep learning: F1-Score 79.69%\n",
      "deep learning: AUC Score 86.13%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       low 0       0.77      0.83      0.80       246\n",
      "      high 1       0.83      0.77      0.80       266\n",
      "\n",
      "    accuracy                           0.80       512\n",
      "   macro avg       0.80      0.80      0.80       512\n",
      "weighted avg       0.80      0.80      0.80       512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, metrics\n",
    "y_pred=model3.predict(X_train)\n",
    "y_pred[y_pred>0.5]=1\n",
    "y_pred[y_pred<0.5]=0\n",
    "\n",
    "cv_preds = y_pred\n",
    "print('rnnamp train datasets')\n",
    "name='deep learning'\n",
    "print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_train, cv_preds)))\n",
    "print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_train, cv_preds)))\n",
    "print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*metrics.matthews_corrcoef(y_train, cv_preds)))\n",
    "print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_train, cv_preds)))\n",
    "print(\"%s: F1-Score %0.2f%%\" % (name, 100*metrics.f1_score(y_train, cv_preds)))\n",
    "print(\"%s: AUC Score %0.2f%%\" % (name, 100*auc))\n",
    "target_names = ['low 0', 'high 1']\n",
    "print(metrics.classification_report(y_train, cv_preds, target_names=target_names))\n",
    "\n",
    "# Predictions Validation Set\n",
    "print('rnnamp test datasets')\n",
    "y_pred2=model3.predict(X_test)\n",
    "l=np.zeros(len(y_pred2))\n",
    "l=l.reshape(-1,1)\n",
    "l[y_pred2>=0.5]=1\n",
    "l[y_pred2<0.5]=0\n",
    "cv_preds2 = l\n",
    "print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_test, cv_preds2)))\n",
    "print(\"%s: Precision %0.2f%%\" % (name, 100*metrics.precision_score(y_test, cv_preds2)))\n",
    "print(\"%s: Recall %0.2f%%\" % (name, 100*metrics.recall_score(y_test, cv_preds2)))\n",
    "print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*metrics.matthews_corrcoef(y_test, cv_preds2)))\n",
    "print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_test, cv_preds2)))\n",
    "print(\"%s: F1-Score %0.2f%%\" % (name, 100*metrics.f1_score(y_test, cv_preds2)))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred2, pos_label=1)\n",
    "auc=metrics.auc(fpr, tpr)\n",
    "print(\"%s: AUC Score %0.2f%%\" % (name, 100*auc))\n",
    "\n",
    "target_names = ['low 0', 'high 1']\n",
    "print(metrics.classification_report(y_test, cv_preds2, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b691e99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T18:28:09.556439Z",
     "iopub.status.busy": "2024-05-06T18:28:09.556093Z",
     "iopub.status.idle": "2024-05-06T18:28:09.695621Z",
     "shell.execute_reply": "2024-05-06T18:28:09.694657Z"
    },
    "id": "k9NxcbR5Lh4f",
    "papermill": {
     "duration": 0.358633,
     "end_time": "2024-05-06T18:28:09.698250",
     "exception": false,
     "start_time": "2024-05-06T18:28:09.339617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model3.save_weights(\"AMAP3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e83315",
   "metadata": {
    "papermill": {
     "duration": 0.213645,
     "end_time": "2024-05-06T18:28:10.124306",
     "exception": false,
     "start_time": "2024-05-06T18:28:09.910661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4241668,
     "sourceId": 7325770,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 37191,
     "sourceId": 44279,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 315.63485,
   "end_time": "2024-05-06T18:28:13.469676",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-06T18:22:57.834826",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
