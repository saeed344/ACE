{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1KQ8NiBVlnI9DFREXghMOW5uyRB-T4L78","authorship_tag":"ABX9TyOVMoxQZ4WFMk9q734RB8DU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m1zHya1UmYv7","executionInfo":{"status":"ok","timestamp":1685293790270,"user_tz":-300,"elapsed":64486,"user":{"displayName":"Dr. Saeed Ahmed","userId":"15898076895818453159"}},"outputId":"361be0ef-5b58-43fc-a0db-cb42ec760a7e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n__dn2v3pLT8","executionInfo":{"status":"ok","timestamp":1685294164802,"user_tz":-300,"elapsed":10430,"user":{"displayName":"Dr. Saeed Ahmed","userId":"15898076895818453159"}},"outputId":"7a9e7806-c237-4721-e659-71cae60ed993"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m115.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HnpLO1z5mIed"},"outputs":[],"source":["import numpy as np\n","from gensim.models import FastText\n","import numpy as np\n","import torch\n","from transformers import BertModel, BertTokenizer\n","\n","import pandas as pd\n","import numpy as np\n","import re, os, sys\n","from itertools import product\n","\n","def read_nucleotide_sequences(file):\n","    if os.path.exists(file) == False:\n","        print('Error: file %s does not exist.' % file)\n","        sys.exit(1)\n","    with open(file) as f:\n","        records = f.read()\n","    if re.search('>', records) == None:\n","        print('Error: the input file %s seems not in FASTA format!' % file)\n","        sys.exit(1)\n","    records = records.split('>')[1:]\n","    fasta_sequences = []\n","    for fasta in records:\n","        array = fasta.split('\\n')\n","        header, sequence = array[0].split()[0], re.sub('[^ACGTU-]', '-', ''.join(array[1:]).upper())\n","        header_array = header.split('|')\n","        name = header_array[0]\n","        label = header_array[1] if len(header_array) >= 2 else '0'\n","        label_train = header_array[2] if len(header_array) >= 3 else 'training'\n","        sequence = re.sub('U', 'T', sequence)\n","        fasta_sequences.append(sequence)\n","    return fasta_sequences\n","\n","#!/usr/bin/env python\n","#_*_coding:utf-8_*_\n","\n","import re\n","\n","def check_fasta_with_equal_length(fastas):\n","    status = True\n","    lenList = set()\n","    for i in fastas:\n","        lenList.add(len(i[1]))\n","    if len(lenList) == 1:\n","        return True\n","    else:\n","        return False\n","\n","def get_min_sequence_length(fastas):\n","    minLen = 10000\n","    for i in fastas:\n","        if minLen > len(i[1]):\n","            minLen = len(i[1])\n","    return minLen\n","\n","def get_min_sequence_length_1(fastas):\n","    minLen = 10000\n","    for i in fastas:\n","        if minLen > len(re.sub('-', '', i[1])):\n","            minLen = len(re.sub('-', '', i[1]))\n","    return minLen\n","def readFasta(file):\n","    if os.path.exists(file) == False:\n","        print('Error: \"' + file + '\" does not exist.')\n","        sys.exit(1)\n","\n","    with open(file) as f:\n","        records = f.read()\n","\n","    if re.search('>', records) == None:\n","        print('The input file seems not in fasta format.')\n","        sys.exit(1)\n","\n","    records = records.split('>')[1:]\n","    myFasta = []\n","    for fasta in records:\n","        array = fasta.split('\\n')\n","        name, sequence = array[0].split()[0], re.sub('[^ARNDCQEGHILKMFPSTWYV-]', '-', ''.join(array[1:]).upper())\n","        myFasta.append([name, sequence])\n","    return myFasta\n","\n","\n","def extract_features(dna_sequences, vector_size=100, window=5, min_count=1):\n","    # Prepare data for FastText\n","    tokenized_sequences = [list(sequence) for sequence in dna_sequences]\n","\n","    # Train FastText model\n","    model = FastText(tokenized_sequences, vector_size=vector_size, window=window, min_count=min_count)\n","\n","    # Extract features\n","    features = np.zeros((len(dna_sequences), vector_size))\n","    for i, sequence in enumerate(tokenized_sequences):\n","        for token in sequence:\n","            features[i] += model.wv[token]\n","        features[i] /= len(sequence)\n","\n","    return features\n","\n","# Example usage\n","dna_sequences = ['ATCGATCGATCG', 'CGATCGATCGATCG']\n","\n","fastas = read_nucleotide_sequences('/content/drive/MyDrive/Research Work/NLP-Features code/balanced_training_datasets/cd_ac4c_training_10.fasta')\n","features = extract_features(fastas)\n","data_csv=pd.DataFrame(features)\n","data_csv.to_csv('/content/drive/MyDrive/Research Work/NLP-Features code/balanced_training_datasets/FastText_feature_training_10.csv')\n","\n","print(features)"]},{"cell_type":"code","source":["!pip install fasttext"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UCQVzFi0-FQW","executionInfo":{"status":"ok","timestamp":1714765382584,"user_tz":-120,"elapsed":69271,"user":{"displayName":"Dr. Saeed Ahmed","userId":"15898076895818453159"}},"outputId":"756a4c69-0953-44b0-8289-10b72e37fe63"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fasttext\n","  Downloading fasttext-0.9.2.tar.gz (68 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/68.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pybind11>=2.2 (from fasttext)\n","  Using cached pybind11-2.12.0-py3-none-any.whl (234 kB)\n","Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.25.2)\n","Building wheels for collected packages: fasttext\n","  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4227141 sha256=5f48c0f3c19a934422880be353c3b9d24f5cd9ff0ae29aebca7bca249f706ee2\n","  Stored in directory: /root/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n","Successfully built fasttext\n","Installing collected packages: pybind11, fasttext\n","Successfully installed fasttext-0.9.2 pybind11-2.12.0\n"]}]},{"cell_type":"code","source":["!pip install biopython"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oFKHmPyuAHt_","executionInfo":{"status":"ok","timestamp":1714765744187,"user_tz":-120,"elapsed":9803,"user":{"displayName":"Dr. Saeed Ahmed","userId":"15898076895818453159"}},"outputId":"309699d7-dafc-48ad-d908-3a78b457ba6e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting biopython\n","  Downloading biopython-1.83-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.25.2)\n","Installing collected packages: biopython\n","Successfully installed biopython-1.83\n"]}]},{"cell_type":"code","source":["import fasttext\n","\n","# Path to your RNA sequence text file\n","data_path = \"/content/drive/MyDrive/Research Work/NLP-Features code/Saweera_data/balanced_training_datasets/cd_ac4c_training_1.fasta\"\n","\n","# Train FastText model\n","model = fasttext.train_unsupervised(data_path, model='cbow', dim=100, epoch=10, minCount=1)\n","\n","# Save the trained model\n","model.save_model(\"rna_fasttext_model.bin\")\n","\n","print(\"Model trained and saved successfully.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0buyVlmu_Rwq","executionInfo":{"status":"ok","timestamp":1714765674117,"user_tz":-120,"elapsed":5475,"user":{"displayName":"Dr. Saeed Ahmed","userId":"15898076895818453159"}},"outputId":"8ea4616a-5de0-4d1e-b7ff-98664610d934"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Model trained and saved successfully.\n"]}]},{"cell_type":"code","source":["import fasttext\n","from Bio import SeqIO\n","import numpy as np\n","import pandas as pd\n","\n","# Load FastText model\n","# model = fasttext.load_model('/content/rna_fasttext_model.bin')  # Pre-trained FastText model, you can replace it with your own trained model\n","# Train FastText model\n","model = fasttext.train_unsupervised(input_file, model='cbow', dim=100, epoch=10, minCount=1)\n","\n","# Function to convert RNA sequence into numerical features\n","def sequence_to_features(sequence, model):\n","    # Tokenize RNA sequence into k-mers (n-grams)\n","    k = 3  # You can adjust the k-mer size\n","    kmers = [sequence[i:i+k] for i in range(len(sequence) - k + 1)]\n","\n","    # Compute FastText embeddings for each k-mer\n","    embeddings = [model.get_word_vector(kmer) for kmer in kmers]\n","\n","    # Calculate mean embedding as the feature representation\n","    if embeddings:\n","        feature = np.mean(embeddings, axis=0)\n","    else:\n","        feature = np.zeros(model.get_dimension())  # Return zero vector if no k-mers found\n","\n","    return feature\n","\n","# Function to read RNA sequences from FASTA file and convert to features\n","def fasta_to_features(input_file, model):\n","    sequences = []\n","    features = []\n","\n","    for record in SeqIO.parse(input_file, \"fasta\"):\n","        sequences.append(str(record.seq))\n","        features.append(sequence_to_features(str(record.seq), model))\n","\n","    return sequences, np.array(features)\n","\n","# Read RNA sequences from FASTA file and convert to features\n","input_file = \"/content/drive/MyDrive/Research Work/NLP-Features code/Saweera_data/balanced_training_datasets/cd_ac4c_training_1.fasta\"\n","sequences, features = fasta_to_features(input_file, model)\n","\n","# Create DataFrame for features\n","columns = [f\"feature_{i+1}\" for i in range(features.shape[1])]\n","df = pd.DataFrame(features, columns=columns)\n","df.insert(0, \"Sequence\", sequences)\n","\n","# Save features as CSV\n","output_file = \"rna_features.csv\"\n","df.to_csv(output_file, index=False)\n","\n","print(\"Features saved to\", output_file)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KqQ-h15b-QnD","executionInfo":{"status":"ok","timestamp":1714766181951,"user_tz":-120,"elapsed":11917,"user":{"displayName":"Dr. Saeed Ahmed","userId":"15898076895818453159"}},"outputId":"f079094d-36e1-42bb-98e2-8e25dc474e3b"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Features saved to rna_features.csv\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"hAcf2GgqmXSk"}}]}