{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2024-06-30T11:07:30.639175Z","iopub.execute_input":"2024-06-30T11:07:30.639613Z","iopub.status.idle":"2024-06-30T11:07:30.666861Z","shell.execute_reply.started":"2024-06-30T11:07:30.639575Z","shell.execute_reply":"2024-06-30T11:07:30.665516Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"/kaggle/input/ace-dataset/ACE_dataset.csv\n/kaggle/input/ace-dataset/all_ACE_auto_features.csv\n/kaggle/input/ace-dataset/ACE_dataset.fasta\n/kaggle/input/ace-dataset/features/ACE_ASDC.csv\n/kaggle/input/ace-dataset/features/opf_7bit_type_1_features.csv\n/kaggle/input/ace-dataset/features/opf_7bit_type_2_features.csv\n/kaggle/input/ace-dataset/features/esmv1_feat_ACE.csv\n/kaggle/input/ace-dataset/features/ACE_embeddings_prot_t5_xl_bfd.csv\n/kaggle/input/ace-dataset/features/esm2_t6_8M_feat_ACE.csv\n/kaggle/input/ace-dataset/features/opf_7bit_type_3_features.csv\n/kaggle/input/ace-dataset/features/opf_10bit_features.csv\n/kaggle/input/ace-dataset/features/ACE_AAC.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install torch==1.13.0\n!install tensorflow==2.8.0\n!pip install tensorflow==2.8.0","metadata":{"execution":{"iopub.status.busy":"2024-06-30T11:07:30.669186Z","iopub.execute_input":"2024-06-30T11:07:30.669686Z","iopub.status.idle":"2024-06-30T11:07:49.244284Z","shell.execute_reply.started":"2024-06-30T11:07:30.669643Z","shell.execute_reply":"2024-06-30T11:07:49.242862Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"^C\nTraceback (most recent call last):\n  File \"/opt/conda/bin/pip\", line 10, in <module>\n    sys.exit(main())\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/cli/main.py\", line 77, in main\n    command = create_command(cmd_name, isolated=(\"--isolated\" in cmd_args))\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/commands/__init__.py\", line 114, in create_command\n    module = importlib.import_module(module_path)\n  File \"/opt/conda/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/commands/install.py\", line 15, in <module>\n    from pip._internal.cli.req_command import (\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/cli/req_command.py\", line 21, in <module>\n    from pip._internal.index.package_finder import PackageFinder\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/index/package_finder.py\", line 30, in <module>\n    from pip._internal.req import InstallRequirement\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/req/__init__.py\", line 8, in <module>\n    from .req_install import InstallRequirement\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/req/req_install.py\", line 40, in <module>\n    from pip._internal.operations.install.wheel import install_wheel\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/operations/install/wheel.py\", line 39, in <module>\n    from pip._vendor.distlib.scripts import ScriptMaker\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_vendor/distlib/scripts.py\", line 17, in <module>\n    from .resources import finder\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_vendor/distlib/resources.py\", line 19, in <module>\n    from .util import cached_property, get_cache_base, Cache\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_vendor/distlib/util.py\", line 23, in <module>\n    import tarfile\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n  File \"<frozen importlib._bootstrap_external>\", line 1012, in get_code\n  File \"<frozen importlib._bootstrap_external>\", line 672, in _compile_bytecode\nKeyboardInterrupt\ninstall: missing destination file operand after 'tensorflow==2.8.0'\nTry 'install --help' for more information.\nRequirement already satisfied: tensorflow==2.8.0 in /opt/conda/lib/python3.10/site-packages (2.8.0)\nRequirement already satisfied: absl-py>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (1.6.3)\nRequirement already satisfied: flatbuffers>=1.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (23.5.26)\nRequirement already satisfied: gast>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (3.10.0)\nRequirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (1.1.2)\nRequirement already satisfied: libclang>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (16.0.6)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (3.3.0)\nRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (4.9.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (1.14.1)\nRequirement already satisfied: tensorboard<2.9,>=2.8 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (2.8.0)\nRequirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (2.8.0.dev2021122109)\nRequirement already satisfied: keras<2.9,>=2.8.0rc0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (2.8.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8.0) (1.60.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.8.0) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.6)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.32.3)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.6.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.8.1)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.0.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Current directory\n# import os\n# os.chdir('F:\\Work\\Experiment\\pLM4ACE\\model')","metadata":{"execution":{"iopub.status.busy":"2024-06-30T11:07:49.246304Z","iopub.execute_input":"2024-06-30T11:07:49.246708Z","iopub.status.idle":"2024-06-30T11:07:49.252886Z","shell.execute_reply.started":"2024-06-30T11:07:49.246673Z","shell.execute_reply":"2024-06-30T11:07:49.251440Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport sklearn.preprocessing as prep\nfrom sklearn.model_selection import train_test_split\nimport csv\n\n# Helper function to standard scale data\ndef standard_scale(X_train, X_test):\n    preprocessor = prep.StandardScaler().fit(X_train)\n    X_train = preprocessor.transform(X_train)\n    X_test = preprocessor.transform(X_test)\n    return X_train, X_test\n# Paths and data loading (adjust paths accordingly)\npath1 = '/kaggle/input/ace-dataset/features/'\nAAC = pd.read_csv(path1 + 'ACE_AAC.csv',header=None).iloc[:, 1:]\nASDC = pd.read_csv(path1 + 'ACE_ASDC.csv',header=None).iloc[:, 1:]\nOPF_7bit_type_1 = pd.read_csv(path1 + 'opf_7bit_type_1_features.csv',header=None).iloc[1:, 1:]\nOPF_7bit_type_2 = pd.read_csv(path1 + 'opf_7bit_type_2_features.csv',header=None).iloc[1:, 1:]\nOPF_7bit_type_3 = pd.read_csv(path1 + 'opf_7bit_type_3_features.csv',header=None).iloc[1:, 1:]\nOPF_10bit = pd.read_csv(path1 + 'opf_10bit_features.csv',header=None).iloc[1:, 1:]\nesmv1 = pd.read_csv(path1 + 'esmv1_feat_ACE.csv',header=None).iloc[:, :]\nesm2 = pd.read_csv(path1 + 'esm2_t6_8M_feat_ACE.csv',header=None).iloc[:, :]\nprot_t5 = pd.read_csv(path1 + 'ACE_embeddings_prot_t5_xl_bfd.csv',header=None).iloc[1:, 1:]\n\n# Concatenate all features into a single array\nall_feat = np.column_stack((AAC, ASDC, OPF_7bit_type_1, OPF_7bit_type_2, OPF_7bit_type_3, OPF_10bit, esmv1, esm2, prot_t5))\n\n# Standard scale the data\nlabel1 = np.ones((394,1))\nlabel2 = np.zeros((626,1))\ny = np.concatenate((label1,label2))\n\nX, _ = standard_scale(all_feat, all_feat)\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T11:07:49.256306Z","iopub.execute_input":"2024-06-30T11:07:49.256785Z","iopub.status.idle":"2024-06-30T11:07:52.224492Z","shell.execute_reply.started":"2024-06-30T11:07:49.256750Z","shell.execute_reply":"2024-06-30T11:07:52.223251Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### Import Data","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nX = pd.read_csv(r\"/kaggle/input/ace-dataset/all_ACE_auto_features.csv\", index_col=None, header=None)\n# y_new = pd.read_csv(\"fusion_features\\Data\\label.csv\", index_col=False, header=None)\n# Standard scale the data\nlabel1 = np.ones((394,1))\nlabel2 = np.zeros((626,1))\ny = np.concatenate((label1,label2))\n\nprint(X.shape)\nprint(y.shape)\nprint(np.count_nonzero(y==0))\nprint(np.count_nonzero(y==1))\n\nX_new = np.array(X)\ny_new = np.array(y)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T11:07:52.225956Z","iopub.execute_input":"2024-06-30T11:07:52.226311Z","iopub.status.idle":"2024-06-30T11:07:53.565213Z","shell.execute_reply.started":"2024-06-30T11:07:52.226282Z","shell.execute_reply":"2024-06-30T11:07:53.563803Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"(1020, 3912)\n(1020, 1)\n626\n394\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Test","metadata":{}},{"cell_type":"code","source":"# K-fold cross validation\nimport os\nimport sys\nimport statistics\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import scale\nfrom keras.layers import Input, Dense\nfrom keras.layers import BatchNormalization\nfrom keras.layers import LeakyReLU\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import adam_v2\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport math\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1111)\n\n# X_train_whole = scale(X_train_whole)\n[sample_num, input_dimwx]=np.shape(X_train)\n\nX = X_train\n\ny = y_train\nout_dim=2\n\noptimizer = adam_v2.Adam(0.5)\nn_y_value = 2\n\nD = Sequential()\nD.add(Dense(64))\nD.add(LeakyReLU(alpha=0.2))\nD.add(Dense(32))\nD.add(Dense(2, activation='sigmoid'))\nimg = Input(shape=(n_y_value,))\nvalidity = D(img)\nDiscriminator = Model(img,validity)\nDiscriminator.compile(loss='binary_crossentropy',\n            optimizer=optimizer,\n            metrics=['binary_accuracy'])\n\n\n##### Build the generator and combine the generator and discriminator models into GAN\nN_ideas = input_dimwx\nG = Sequential()\nG.add(Dense(64,input_dim=N_ideas))\nG.add(LeakyReLU(alpha=0.2))\nG.add(BatchNormalization(momentum=0.8))\nG.add(Dense(64))\nG.add(LeakyReLU(alpha=0.2))\nG.add(BatchNormalization(momentum=0.8))\nG.add(Dense(32))\nG.add(LeakyReLU(alpha=0.2))\nG.add(BatchNormalization(momentum=0.8))\nG.add(Dense(n_y_value, activation='tanh'))\nnoise = Input(shape=(N_ideas,))\nG_img = G(noise)\nGenerator = Model(noise,G_img)\n\nz = Input(shape=(N_ideas,))\nG_img = Generator(z)\nDiscriminator.trainable = False\nvalidity = Discriminator(G_img)\nGAN = Model(z,validity)\nGAN.compile(loss='binary_crossentropy', optimizer=optimizer, metrics =['binary_accuracy'])\n\nBACC_collecton = []\nSn_collecton = []\nSp_collecton = []\nMCC_collecton = []\nAUC_collecton = []\nAP=[]\n\nmean_recall = np.linspace(0, 1, 100)\nall_precision = []\nbase_fpr = np.linspace(0, 1, 100)\nmean_tpr = 0.0\n# New TPR Collection\ninterp_tpr_collection = []\n\n\ndef categorical_probas_to_classes(p):\n    return np.argmax(p, axis=1)\n\n\ndef to_categorical(y, nb_classes=None):\n    y = np.array(y, dtype='int')\n    if not nb_classes:\n        nb_classes = np.max(y)+1\n    Y = np.zeros((len(y), nb_classes))\n    for i in range(len(y)):\n        Y[i, y[i]] = 1\n    return Y\n\n# Define the directory to save the models\nsave_dir = '/kaggle/working/models/'\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\nskf = StratifiedKFold(n_splits=10)\nfor train, test in skf.split(X, y):\n    X_train, X_valid, y_train, y_valid = np.take(X, train.tolist(), axis=0), np.take(X, test.tolist(), axis=0), np.take(y, train.tolist(), axis=0), np.take(y, test.tolist(), axis=0)\n    \n    y_train = to_categorical(y_train)\n\n    clf = GAN\n    hist = clf.fit(X_train, y_train, batch_size=64, epochs=60)#validation_data=(X_valid, to_categorical(y_valid)\n    y_score = clf.predict(X_valid)\n    y_class = categorical_probas_to_classes(y_score)\n    TP, FP, FN, TN = confusion_matrix(y_valid, y_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n    Sn_collecton.append(TP/(TP+FN))\n    Sp_collecton.append(TN/(TN+FP))\n    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n    MCC_collecton.append(MCC)\n    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n    # ROC curve\n    fpr, tpr, _ = roc_curve(y_valid, y_score[:, 1])\n    interp_tpr = np.interp(base_fpr, fpr, tpr)\n    interp_tpr[0] = 0.0\n    interp_tpr_collection.append(interp_tpr)\n    auc_roc = auc(fpr, tpr)\n    AUC_collecton.append(auc_roc)\n    # PR curve\n    precision, recall, _ = precision_recall_curve(y_valid, y_score[:, 1])\n    average_precision = average_precision_score(y_valid, y_score[:, 1])\n    recall = np.flipud(recall)\n    precision = np.flipud(precision)\n\n    mean_precision = np.interp(mean_recall, recall, precision)\n    all_precision.append(mean_precision)\n    AP.append(average_precision)\n     # Save the trained models\n#     generator.save(os.path.join(save_dir, f'generator_model_fold_{fold+1}.h5'))\n#     discriminator.save(os.path.join(save_dir, f'discriminator_model_fold_{fold+1}.h5'))\n\n# Output\nprint('BACC :',round(statistics.mean(BACC_collecton),3),'±',round(statistics.stdev(BACC_collecton),3))\nprint('Sn :',round(statistics.mean(Sn_collecton),3),'±',round(statistics.stdev(Sn_collecton),3))\nprint('Sp :',round(statistics.mean(Sp_collecton),3),'±',round(statistics.stdev(Sp_collecton),3))\nprint('MCC :',round(statistics.mean(MCC_collecton),3),'±',round(statistics.stdev(MCC_collecton),3))\nprint('AUC :',round(statistics.mean(AUC_collecton),3),'±',round(statistics.stdev(AUC_collecton),3))\nprint('AP :',round(statistics.mean(AP),3),'±',round(statistics.stdev(AP),3))\n\n# After all cross-validation fold, the mean TPR is calculated.\nmean_tpr = np.mean(interp_tpr_collection, axis=0)\nmean_tpr[-1] = 1.0\n\n# Calculate the mean precision\nmean_precision = np.mean(all_precision, axis=0)\n\n# Save ROC curve related parameters\nnp.savez(r'Draw graphics\\ROC curve\\GAN_PCA_All_cross_vaild.npz', fpr=base_fpr, tpr=mean_tpr, roc_auc=AUC_collecton)\n\n# Save PR curve related parameters\nnp.savez(r'Draw graphics\\PR curve\\GAN_PCA_All_cross_vaild.npz', recall=mean_recall, precision=mean_precision, average_precision=AP)\n\n# Plotting the ROC Curve\nplt.figure()\nlw = 2\nplt.plot(base_fpr, mean_tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % np.mean(AUC_collecton))\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([-0.05, 1.05])\nplt.ylim([-0.05, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('10 k-fold cross vaild')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T11:09:35.558658Z","iopub.execute_input":"2024-06-30T11:09:35.559072Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/60\n8/8 [==============================] - 1s 7ms/step - loss: 0.6771 - binary_accuracy: 0.6154\nEpoch 2/60\n8/8 [==============================] - 0s 7ms/step - loss: 0.6745 - binary_accuracy: 0.6143\nEpoch 3/60\n8/8 [==============================] - 0s 7ms/step - loss: 0.6738 - binary_accuracy: 0.6229\nEpoch 4/60\n8/8 [==============================] - 0s 7ms/step - loss: 0.6712 - binary_accuracy: 0.6432\nEpoch 5/60\n8/8 [==============================] - 0s 8ms/step - loss: 0.6713 - binary_accuracy: 0.6421\nEpoch 6/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6688 - binary_accuracy: 0.6624\nEpoch 7/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6668 - binary_accuracy: 0.6763\nEpoch 8/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6763 - binary_accuracy: 0.6261\nEpoch 9/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6910 - binary_accuracy: 0.5556\nEpoch 10/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6736 - binary_accuracy: 0.6357\nEpoch 11/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6698 - binary_accuracy: 0.6549\nEpoch 12/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6691 - binary_accuracy: 0.6613\nEpoch 13/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6744 - binary_accuracy: 0.6218\nEpoch 14/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6743 - binary_accuracy: 0.6207\nEpoch 15/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6738 - binary_accuracy: 0.6250\nEpoch 16/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6753 - binary_accuracy: 0.6143\nEpoch 17/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6744 - binary_accuracy: 0.6207\nEpoch 18/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6741 - binary_accuracy: 0.6229\nEpoch 19/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6745 - binary_accuracy: 0.6197\nEpoch 20/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6747 - binary_accuracy: 0.6186\nEpoch 21/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6739 - binary_accuracy: 0.6250\nEpoch 22/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6732 - binary_accuracy: 0.6303\nEpoch 23/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6734 - binary_accuracy: 0.6293\nEpoch 24/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6731 - binary_accuracy: 0.6314\nEpoch 25/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6734 - binary_accuracy: 0.6293\nEpoch 26/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6726 - binary_accuracy: 0.6346\nEpoch 27/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6732 - binary_accuracy: 0.6303\nEpoch 28/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6729 - binary_accuracy: 0.6325\nEpoch 29/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6729 - binary_accuracy: 0.6325\nEpoch 30/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6728 - binary_accuracy: 0.6335\nEpoch 31/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6732 - binary_accuracy: 0.6303\nEpoch 32/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6731 - binary_accuracy: 0.6314\nEpoch 33/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6729 - binary_accuracy: 0.6325\nEpoch 34/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6721 - binary_accuracy: 0.6378\nEpoch 35/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6727 - binary_accuracy: 0.6335\nEpoch 36/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6726 - binary_accuracy: 0.6346\nEpoch 37/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6727 - binary_accuracy: 0.6335\nEpoch 38/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6724 - binary_accuracy: 0.6357\nEpoch 39/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6726 - binary_accuracy: 0.6335\nEpoch 40/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6716 - binary_accuracy: 0.6432\nEpoch 41/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6714 - binary_accuracy: 0.6485\nEpoch 42/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6718 - binary_accuracy: 0.6432\nEpoch 43/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6729 - binary_accuracy: 0.6357\nEpoch 44/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6704 - binary_accuracy: 0.6485\nEpoch 45/60\n8/8 [==============================] - 0s 5ms/step - loss: 0.6697 - binary_accuracy: 0.6538\nEpoch 46/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6683 - binary_accuracy: 0.6635\nEpoch 47/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6743 - binary_accuracy: 0.6175\nEpoch 48/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6698 - binary_accuracy: 0.6517\nEpoch 49/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6704 - binary_accuracy: 0.6464\nEpoch 50/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6703 - binary_accuracy: 0.6474\nEpoch 51/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6697 - binary_accuracy: 0.6528\nEpoch 52/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6692 - binary_accuracy: 0.6571\nEpoch 53/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6694 - binary_accuracy: 0.6560\nEpoch 54/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6706 - binary_accuracy: 0.6485\nEpoch 55/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6723 - binary_accuracy: 0.6368\nEpoch 56/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6736 - binary_accuracy: 0.6282\nEpoch 57/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6734 - binary_accuracy: 0.6293\nEpoch 58/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6734 - binary_accuracy: 0.6293\nEpoch 59/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6734 - binary_accuracy: 0.6293\nEpoch 60/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6736 - binary_accuracy: 0.6282\nEpoch 1/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 2/60\n1/8 [==>...........................] - ETA: 0s - loss: 0.6683 - binary_accuracy: 0.6562","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/1313598445.py:117: RuntimeWarning: invalid value encountered in scalar divide\n  Sp_collecton.append(TN/(TN+FP))\n/tmp/ipykernel_33/1313598445.py:118: RuntimeWarning: invalid value encountered in divide\n  MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n/tmp/ipykernel_33/1313598445.py:120: RuntimeWarning: invalid value encountered in scalar divide\n  BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n","output_type":"stream"},{"name":"stdout","text":"8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 3/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 4/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6738 - binary_accuracy: 0.6269\nEpoch 5/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 6/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 7/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 8/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 9/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 10/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 11/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6731 - binary_accuracy: 0.6322\nEpoch 12/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 13/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 14/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6734 - binary_accuracy: 0.6301\nEpoch 15/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 16/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 17/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 18/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 19/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6734 - binary_accuracy: 0.6301\nEpoch 20/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 21/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 22/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 23/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 24/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 25/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 26/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 27/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 28/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6732 - binary_accuracy: 0.6311\nEpoch 29/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 30/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 31/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 32/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 33/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 34/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6738 - binary_accuracy: 0.6269\nEpoch 35/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 36/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6738 - binary_accuracy: 0.6269\nEpoch 37/60\n8/8 [==============================] - 0s 5ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 38/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 39/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 40/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 41/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6738 - binary_accuracy: 0.6269\nEpoch 42/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 43/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 44/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6738 - binary_accuracy: 0.6269\nEpoch 45/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 46/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 47/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6734 - binary_accuracy: 0.6301\nEpoch 48/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 49/60\n8/8 [==============================] - 0s 5ms/step - loss: 0.6738 - binary_accuracy: 0.6269\nEpoch 50/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 51/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 52/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 53/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6738 - binary_accuracy: 0.6269\nEpoch 54/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6738 - binary_accuracy: 0.6269\nEpoch 55/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 56/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6738 - binary_accuracy: 0.6269\nEpoch 57/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6738 - binary_accuracy: 0.6269\nEpoch 58/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6738 - binary_accuracy: 0.6269\nEpoch 59/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 60/60\n8/8 [==============================] - 0s 5ms/step - loss: 0.6738 - binary_accuracy: 0.6269\nEpoch 1/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 2/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 3/60\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/1313598445.py:117: RuntimeWarning: invalid value encountered in scalar divide\n  Sp_collecton.append(TN/(TN+FP))\n/tmp/ipykernel_33/1313598445.py:118: RuntimeWarning: invalid value encountered in divide\n  MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n/tmp/ipykernel_33/1313598445.py:120: RuntimeWarning: invalid value encountered in scalar divide\n  BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n","output_type":"stream"},{"name":"stdout","text":"8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 4/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 5/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6734 - binary_accuracy: 0.6301\nEpoch 6/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 7/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 8/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 9/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 10/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 11/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 12/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 13/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 14/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 15/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 16/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 17/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6738 - binary_accuracy: 0.6269\nEpoch 18/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 19/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 20/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 21/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 22/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 23/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 24/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 25/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 26/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 27/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6738 - binary_accuracy: 0.6269\nEpoch 28/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 29/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6738 - binary_accuracy: 0.6269\nEpoch 30/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 31/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 32/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 33/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6738 - binary_accuracy: 0.6269\nEpoch 34/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 35/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6740 - binary_accuracy: 0.6258\nEpoch 36/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 37/60\n8/8 [==============================] - 0s 7ms/step - loss: 0.6738 - binary_accuracy: 0.6269\nEpoch 38/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6740 - binary_accuracy: 0.6258\nEpoch 39/60\n8/8 [==============================] - 0s 7ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 40/60\n8/8 [==============================] - 0s 9ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 41/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 42/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6740 - binary_accuracy: 0.6258\nEpoch 43/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6738 - binary_accuracy: 0.6269\nEpoch 44/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 45/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 46/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 47/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 48/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 49/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6734 - binary_accuracy: 0.6301\nEpoch 50/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 51/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 52/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 53/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 54/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 55/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 56/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 57/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 58/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6734 - binary_accuracy: 0.6301\nEpoch 59/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 60/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 1/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 2/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 3/60\n1/8 [==>...........................] - ETA: 0s - loss: 0.6800 - binary_accuracy: 0.5938","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/1313598445.py:117: RuntimeWarning: invalid value encountered in scalar divide\n  Sp_collecton.append(TN/(TN+FP))\n/tmp/ipykernel_33/1313598445.py:118: RuntimeWarning: invalid value encountered in divide\n  MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n/tmp/ipykernel_33/1313598445.py:120: RuntimeWarning: invalid value encountered in scalar divide\n  BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n","output_type":"stream"},{"name":"stdout","text":"8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 4/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 5/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6734 - binary_accuracy: 0.6301\nEpoch 6/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6732 - binary_accuracy: 0.6311\nEpoch 7/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 8/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 9/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 10/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 11/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6734 - binary_accuracy: 0.6301\nEpoch 12/60\n8/8 [==============================] - 0s 7ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 13/60\n8/8 [==============================] - 0s 7ms/step - loss: 0.6734 - binary_accuracy: 0.6301\nEpoch 14/60\n8/8 [==============================] - 0s 7ms/step - loss: 0.6734 - binary_accuracy: 0.6301\nEpoch 15/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 16/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6734 - binary_accuracy: 0.6301\nEpoch 17/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6734 - binary_accuracy: 0.6301\nEpoch 18/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6734 - binary_accuracy: 0.6301\nEpoch 19/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 20/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 21/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 22/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 23/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 24/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 25/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 26/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 27/60\n8/8 [==============================] - 0s 7ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 28/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 29/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 30/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 31/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 32/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 33/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 34/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 35/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 36/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 37/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 38/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 39/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 40/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 41/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 42/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 43/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 44/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 45/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 46/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 47/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 48/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 49/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 50/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 51/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 52/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 53/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 54/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 55/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 56/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 57/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 58/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 59/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 60/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 1/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 2/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 3/60\n1/8 [==>...........................] - ETA: 0s - loss: 0.6829 - binary_accuracy: 0.5781","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/1313598445.py:117: RuntimeWarning: invalid value encountered in scalar divide\n  Sp_collecton.append(TN/(TN+FP))\n/tmp/ipykernel_33/1313598445.py:118: RuntimeWarning: invalid value encountered in divide\n  MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n/tmp/ipykernel_33/1313598445.py:120: RuntimeWarning: invalid value encountered in scalar divide\n  BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n","output_type":"stream"},{"name":"stdout","text":"8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 4/60\n8/8 [==============================] - 0s 5ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 5/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 6/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 7/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 8/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 9/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 10/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 11/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 12/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 13/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 14/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 15/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 16/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 17/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 18/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 19/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 20/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 21/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 22/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 23/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 24/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 25/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 26/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 27/60\n8/8 [==============================] - 0s 7ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 28/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 29/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 30/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 31/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 32/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 33/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 34/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6737 - binary_accuracy: 0.6279\nEpoch 35/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6735 - binary_accuracy: 0.6290\nEpoch 36/60\n8/8 [==============================] - 0s 5ms/step - loss: 0.6723 - binary_accuracy: 0.6375\nEpoch 37/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6661 - binary_accuracy: 0.6823\nEpoch 38/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6702 - binary_accuracy: 0.6557\nEpoch 39/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6657 - binary_accuracy: 0.6887\nEpoch 40/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6667 - binary_accuracy: 0.6823\nEpoch 41/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6777 - binary_accuracy: 0.5938\nEpoch 42/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6785 - binary_accuracy: 0.5874\nEpoch 43/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6785 - binary_accuracy: 0.5874\nEpoch 44/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6784 - binary_accuracy: 0.5874\nEpoch 45/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6760 - binary_accuracy: 0.6045\nEpoch 46/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6771 - binary_accuracy: 0.5970\nEpoch 47/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6756 - binary_accuracy: 0.6077\nEpoch 48/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6752 - binary_accuracy: 0.6109\nEpoch 49/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6744 - binary_accuracy: 0.6162\nEpoch 50/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6747 - binary_accuracy: 0.6141\nEpoch 51/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6832 - binary_accuracy: 0.5544\nEpoch 52/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6899 - binary_accuracy: 0.5053\nEpoch 53/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6910 - binary_accuracy: 0.4979\nEpoch 54/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6912 - binary_accuracy: 0.4968\nEpoch 55/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6910 - binary_accuracy: 0.4989\nEpoch 56/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6907 - binary_accuracy: 0.4979\nEpoch 57/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6911 - binary_accuracy: 0.4968\nEpoch 58/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6913 - binary_accuracy: 0.4957\nEpoch 59/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6912 - binary_accuracy: 0.4968\nEpoch 60/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6912 - binary_accuracy: 0.4968\nEpoch 1/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6914 - binary_accuracy: 0.4957\nEpoch 2/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6910 - binary_accuracy: 0.4968\nEpoch 3/60\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/1313598445.py:117: RuntimeWarning: invalid value encountered in scalar divide\n  Sp_collecton.append(TN/(TN+FP))\n/tmp/ipykernel_33/1313598445.py:118: RuntimeWarning: invalid value encountered in divide\n  MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n/tmp/ipykernel_33/1313598445.py:120: RuntimeWarning: invalid value encountered in scalar divide\n  BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n","output_type":"stream"},{"name":"stdout","text":"8/8 [==============================] - 0s 6ms/step - loss: 0.6905 - binary_accuracy: 0.5000\nEpoch 4/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6907 - binary_accuracy: 0.5000\nEpoch 5/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6911 - binary_accuracy: 0.4968\nEpoch 6/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6914 - binary_accuracy: 0.4968\nEpoch 7/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6914 - binary_accuracy: 0.4957\nEpoch 8/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6911 - binary_accuracy: 0.4968\nEpoch 9/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6930 - binary_accuracy: 0.5000\nEpoch 10/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6956 - binary_accuracy: 0.4989\nEpoch 11/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6955 - binary_accuracy: 0.4989\nEpoch 12/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6955 - binary_accuracy: 0.4989\nEpoch 13/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6948 - binary_accuracy: 0.4989\nEpoch 14/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6944 - binary_accuracy: 0.4979\nEpoch 15/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6942 - binary_accuracy: 0.4979\nEpoch 16/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6941 - binary_accuracy: 0.4979\nEpoch 17/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 18/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 19/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 20/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 21/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 22/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 23/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 24/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 25/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 26/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 27/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 28/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 29/60\n8/8 [==============================] - 0s 5ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 30/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 31/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 32/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 33/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 34/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 35/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 36/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 37/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 38/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 39/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 40/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 41/60\n8/8 [==============================] - 0s 9ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 42/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 43/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 44/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 45/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 46/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 47/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 48/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 49/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 50/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 51/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 52/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 53/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 54/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 55/60\n8/8 [==============================] - 0s 5ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 56/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 57/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 58/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 59/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 60/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 1/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 2/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 3/60\n1/8 [==>...........................] - ETA: 0s - loss: 0.6974 - binary_accuracy: 0.5000","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/1313598445.py:117: RuntimeWarning: invalid value encountered in scalar divide\n  Sp_collecton.append(TN/(TN+FP))\n/tmp/ipykernel_33/1313598445.py:118: RuntimeWarning: invalid value encountered in divide\n  MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n/tmp/ipykernel_33/1313598445.py:120: RuntimeWarning: invalid value encountered in scalar divide\n  BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n","output_type":"stream"},{"name":"stdout","text":"8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 4/60\n8/8 [==============================] - 0s 5ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 5/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 6/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 7/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 8/60\n8/8 [==============================] - 0s 5ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 9/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 10/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 11/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 12/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 13/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 14/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 15/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 16/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 17/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 18/60\n8/8 [==============================] - 0s 7ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 19/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 20/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 21/60\n8/8 [==============================] - 0s 5ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 22/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 23/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 24/60\n8/8 [==============================] - 0s 5ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 25/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 26/60\n8/8 [==============================] - 0s 5ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 27/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 28/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 29/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 30/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 31/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 32/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 33/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 34/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 35/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 36/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 37/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 38/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 39/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 40/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 41/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 42/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 43/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 44/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 45/60\n8/8 [==============================] - 0s 5ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 46/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 47/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 48/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 49/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 50/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 51/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 52/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 53/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 54/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 55/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 56/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 57/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 58/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 59/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 60/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5000\nEpoch 1/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6938 - binary_accuracy: 0.5000\nEpoch 2/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6938 - binary_accuracy: 0.5000\nEpoch 3/60\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/1313598445.py:117: RuntimeWarning: invalid value encountered in scalar divide\n  Sp_collecton.append(TN/(TN+FP))\n/tmp/ipykernel_33/1313598445.py:118: RuntimeWarning: invalid value encountered in divide\n  MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n/tmp/ipykernel_33/1313598445.py:120: RuntimeWarning: invalid value encountered in scalar divide\n  BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n","output_type":"stream"},{"name":"stdout","text":"8/8 [==============================] - 0s 6ms/step - loss: 0.6938 - binary_accuracy: 0.5000\nEpoch 4/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6938 - binary_accuracy: 0.5000\nEpoch 5/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6938 - binary_accuracy: 0.5000\nEpoch 6/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6938 - binary_accuracy: 0.5000\nEpoch 7/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6938 - binary_accuracy: 0.5000\nEpoch 8/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6938 - binary_accuracy: 0.5000\nEpoch 9/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6938 - binary_accuracy: 0.5000\nEpoch 10/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6938 - binary_accuracy: 0.5000\nEpoch 11/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6938 - binary_accuracy: 0.5000\nEpoch 12/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6938 - binary_accuracy: 0.5000\nEpoch 13/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6938 - binary_accuracy: 0.5000\nEpoch 14/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6938 - binary_accuracy: 0.5000\nEpoch 15/60\n8/8 [==============================] - 0s 5ms/step - loss: 0.6938 - binary_accuracy: 0.5000\nEpoch 16/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6938 - binary_accuracy: 0.5000\nEpoch 17/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6938 - binary_accuracy: 0.5000\nEpoch 18/60\n8/8 [==============================] - 0s 6ms/step - loss: 0.6938 - binary_accuracy: 0.5000\nEpoch 19/60\n1/8 [==>...........................] - ETA: 0s - loss: 0.6942 - binary_accuracy: 0.5000","output_type":"stream"}]},{"cell_type":"code","source":"# Independent test set\nimport statistics\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import scale\nfrom keras.layers import Input, Dense\nfrom keras.layers import BatchNormalization\nfrom keras.layers import LeakyReLU\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import adam_v2\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport math\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.model_selection import train_test_split\n\n\n# X_new = scale(X_new)\n[sample_num,input_dimwx]=np.shape(X_new)\nX = X_new\n\ny = y_new\nout_dim=2\n\noptimizer = adam_v2.Adam(0.0002, 0.5)\nn_y_value = 2\n\nD = Sequential()\nD.add(Dense(64))\nD.add(LeakyReLU(alpha=0.2))\nD.add(Dense(32))\nD.add(Dense(2, activation='sigmoid'))\nimg = Input(shape=(n_y_value,))\nvalidity = D(img)\nDiscriminator = Model(img,validity)\nDiscriminator.compile(loss='binary_crossentropy',\n            optimizer=optimizer,\n            metrics=['binary_accuracy'])\n\n\n#####Build the generator and combine the generator and discriminator into GAN\nN_ideas = input_dimwx\nG = Sequential()\nG.add(Dense(64,input_dim=N_ideas))\nG.add(LeakyReLU(alpha=0.2))\nG.add(BatchNormalization(momentum=0.8))\nG.add(Dense(64))\nG.add(LeakyReLU(alpha=0.2))\nG.add(BatchNormalization(momentum=0.8))\nG.add(Dense(32))\nG.add(LeakyReLU(alpha=0.2))\nG.add(BatchNormalization(momentum=0.8))\nG.add(Dense(n_y_value, activation='tanh'))\nnoise = Input(shape=(N_ideas,))\nG_img = G(noise)\nGenerator = Model(noise,G_img)\n\nz = Input(shape=(N_ideas,))\nG_img = Generator(z)\nDiscriminator.trainable = False\nvalidity = Discriminator(G_img)\nGAN = Model(z,validity)\nGAN.compile(loss='binary_crossentropy', optimizer=optimizer, metrics =['binary_accuracy'])\n\nBACC_collecton = []\nSn_collecton = []\nSp_collecton = []\nMCC_collecton = []\nAUC_collecton = []\nAP=[]\nmean_recall = np.linspace(0, 1, 100)\nall_precision = []\n\nbase_fpr = np.linspace(0, 1, 100)\nmean_tpr = 0.0\n# New TPR Collection\ninterp_tpr_collection = []\n\n\ndef categorical_probas_to_classes(p):\n    return np.argmax(p, axis=1)\n\n\ndef to_categorical(y, nb_classes=None):\n    y = np.array(y, dtype='int')\n    if not nb_classes:\n        nb_classes = np.max(y)+1\n    Y = np.zeros((len(y), nb_classes))\n    for i in range(len(y)):\n        Y[i, y[i]] = 1\n    return Y\n\nfor i in range(10):\n    # dataset splitting\n    X_train_whole, X_ind_test, y_train_whole, y_ind_test = train_test_split(X, y, test_size=0.2, random_state=i)\n\n    y_train = to_categorical(y_train_whole)\n\n    clf = GAN\n    hist = clf.fit(X_train_whole, y_train, batch_size=64, epochs=60)\n    y_score = clf.predict(X_ind_test)\n    y_class = categorical_probas_to_classes(y_score)\n    TP, FP, FN, TN = confusion_matrix(y_ind_test, y_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n    Sn_collecton.append(TP/(TP+FN))\n    Sp_collecton.append(TN/(TN+FP))\n    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n    MCC_collecton.append(MCC)\n    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n    # ROC curve\n    fpr, tpr, _ = roc_curve(y_ind_test, y_score[:, 1])\n    interp_tpr = np.interp(base_fpr, fpr, tpr)\n    interp_tpr[0] = 0.0\n    interp_tpr_collection.append(interp_tpr)\n    auc_roc = auc(fpr, tpr)\n    AUC_collecton.append(auc_roc)\n    # PR curve\n    precision, recall, _ = precision_recall_curve(y_ind_test, y_score[:, 1])\n    average_precision = average_precision_score(y_ind_test, y_score[:, 1])\n    recall = np.flipud(recall)\n    precision = np.flipud(precision)\n\n    mean_precision = np.interp(mean_recall, recall, precision)\n    all_precision.append(mean_precision)\n    AP.append(average_precision)\n\n# Output\nprint(round(statistics.mean(BACC_collecton),3),'±',round(statistics.stdev(BACC_collecton),3))\nprint(round(statistics.mean(Sn_collecton),3),'±',round(statistics.stdev(Sn_collecton),3))\nprint(round(statistics.mean(Sp_collecton),3),'±',round(statistics.stdev(Sp_collecton),3))\nprint(round(statistics.mean(MCC_collecton),3),'±',round(statistics.stdev(MCC_collecton),3))\nprint(round(statistics.mean(AUC_collecton),3),'±',round(statistics.stdev(AUC_collecton),3))\nprint(round(statistics.mean(AP),3),'±',round(statistics.stdev(AP),3))\n\n# After all cross-validation fold, the mean TPR is calculated.\nmean_tpr = np.mean(interp_tpr_collection, axis=0)\nmean_tpr[-1] = 1.0\n\n# Calculate the mean precision\nmean_precision = np.mean(all_precision, axis=0)\n\n# Save ROC curve related parameters\nnp.savez(r'Draw graphics\\ROC curve\\GAN_PCA_All_Indenpendence.npz', fpr=base_fpr, tpr=mean_tpr, roc_auc=AUC_collecton)\n\n# Save PR curve related parameters\nnp.savez(r'Draw graphics\\PR curve\\GAN_PCA_All_Indenpendence.npz', recall=mean_recall, precision=mean_precision, average_precision=AP)\n\n# Draw ROC curve\nplt.figure()\nlw = 2\nplt.plot(base_fpr, mean_tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % np.mean(AUC_collecton))\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([-0.05, 1.05])\nplt.ylim([-0.05, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Independence test')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-30T11:08:13.652197Z","iopub.status.idle":"2024-06-30T11:08:13.652787Z","shell.execute_reply.started":"2024-06-30T11:08:13.652512Z","shell.execute_reply":"2024-06-30T11:08:13.652536Z"},"trusted":true},"execution_count":null,"outputs":[]}]}