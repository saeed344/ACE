{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3322451,"sourceType":"datasetVersion","datasetId":2008432}],"dockerImageVersionId":30176,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-20T07:18:41.763567Z","iopub.execute_input":"2024-07-20T07:18:41.763927Z","iopub.status.idle":"2024-07-20T07:18:41.772312Z","shell.execute_reply.started":"2024-07-20T07:18:41.763893Z","shell.execute_reply":"2024-07-20T07:18:41.771234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install jpype1","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:11:04.013738Z","iopub.status.idle":"2024-07-25T18:11:04.014207Z","shell.execute_reply.started":"2024-07-25T18:11:04.013951Z","shell.execute_reply":"2024-07-25T18:11:04.013991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/nuclear-smile/PR_with_class_label.csv')\nprint(df)\nsmiles = df['SMILES'].values\ny_all = df['Activity'].values\ny_all[y_all=='active'] = 0\ny_all[y_all=='inactive'] = 1\nall_pos_idx = np.where(y_all==0)[0]\nall_neg_idx = np.where(y_all==1)[0]\nnumPos = sum(y_all==0)\nnumNeg = sum(y_all==1)\nrng = np.random.RandomState(0)\npos_idx_tr = list(rng.choice(all_pos_idx, int(numPos*0.8), replace=False))\nneg_idx_tr = list(rng.choice(all_neg_idx, int(numNeg*0.8), replace=False))\npos_idx_ts = list(set(all_pos_idx) - set(pos_idx_tr))\nneg_idx_ts = list(set(all_neg_idx) - set(neg_idx_tr))\n\nsmiles_tr = smiles[pos_idx_tr + neg_idx_tr]\nsmiles_ts = smiles[pos_idx_ts + neg_idx_ts]\ny = np.hstack((np.zeros(len(pos_idx_tr)), np.ones(len(neg_idx_tr))))\nyt = np.hstack((np.zeros(len(pos_idx_ts)), np.ones(len(neg_idx_ts))))","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:11:04.015545Z","iopub.status.idle":"2024-07-25T18:11:04.016138Z","shell.execute_reply.started":"2024-07-25T18:11:04.015799Z","shell.execute_reply":"2024-07-25T18:11:04.015828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from jpype import isJVMStarted, startJVM, getDefaultJVMPath, JPackage\nif not isJVMStarted():\n    cdk_path = '../input/nuclear-smile/cdk-2.7.1.jar'\n    startJVM(getDefaultJVMPath(), \"-ea\", \"-Djava.class.path=%s\" % cdk_path)\n    cdk =  JPackage('org').openscience.cdk","metadata":{"execution":{"iopub.status.busy":"2022-03-19T08:52:10.201397Z","iopub.execute_input":"2022-03-19T08:52:10.20227Z","iopub.status.idle":"2022-03-19T08:52:11.403896Z","shell.execute_reply.started":"2022-03-19T08:52:10.202212Z","shell.execute_reply":"2022-03-19T08:52:11.402947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def featsmi(fp_type, smis, size=1024, depth=6):\n    fg = {\n            \"AP2D\" : cdk.fingerprint.AtomPairs2DFingerprinter(),\n            \"CKD\":cdk.fingerprint.Fingerprinter(size, depth),\n            \"CKDExt\":cdk.fingerprint.ExtendedFingerprinter(size, depth),\n            \"CKDGraph\":cdk.fingerprint.GraphOnlyFingerprinter(size, depth),\n            \"MACCS\":cdk.fingerprint.MACCSFingerprinter(),\n            \"PubChem\":cdk.fingerprint.PubchemFingerprinter(cdk.silent.SilentChemObjectBuilder.getInstance()),\n            \"Estate\":cdk.fingerprint.EStateFingerprinter(),\n            \"KR\":cdk.fingerprint.KlekotaRothFingerprinter(),\n            \"FP4\" : cdk.fingerprint.SubstructureFingerprinter(),\n            \"FP4C\" : cdk.fingerprint.SubstructureFingerprinter(),\n            \"Circle\" : cdk.fingerprint.CircularFingerprinter(),\n            \"Hybrid\" : cdk.fingerprint.HybridizationFingerprinter(),\n         }\n    sp = cdk.smiles.SmilesParser(cdk.DefaultChemObjectBuilder.getInstance())\n    for i,smi in enumerate(smis):\n        mol = sp.parseSmiles(smi)\n        if fp_type == \"FP4C\":\n            fingerprinter = fg[fp_type]\n            nbit = fingerprinter.getSize()\n            fp = fingerprinter.getCountFingerprint(mol)\n            feat = np.array([int(fp.getCount(i)) for i in range(nbit)])           \n        else:\n            fingerprinter = fg[fp_type]\n            nbit = fingerprinter.getSize()\n            fp = fingerprinter.getFingerprint(mol)\n            feat = np.array([int(fp.get(i)) for i in range(nbit)])\n        if i == 0:\n            featx = feat.reshape(1,-1)\n        else:\n            featx = np.vstack((featx, feat.reshape(1,-1)))\n    return featx\n","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:12:58.544738Z","iopub.execute_input":"2022-03-19T09:12:58.545149Z","iopub.status.idle":"2022-03-19T09:12:58.560125Z","shell.execute_reply.started":"2022-03-19T09:12:58.545113Z","shell.execute_reply":"2022-03-19T09:12:58.558913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file = open('PLS.py','w')\nfile.write('import numpy as np'+\"\\n\")\nfile.write('from sklearn.cross_decomposition import PLSRegression'+\"\\n\")\nfile.write('from sklearn.base import BaseEstimator, ClassifierMixin'+\"\\n\")\nfile.write('class PLS(BaseEstimator, ClassifierMixin):'+\"\\n\")\nfile.write('    def __init__(self):'+\"\\n\")\nfile.write('        self.clf = PLSRegression(n_components=2)'+\"\\n\")\nfile.write('    def fit(self, X, y):'+\"\\n\")\nfile.write('        self.clf.fit(X,y)'+\"\\n\")\nfile.write('        return self'+\"\\n\")\nfile.write('    def predict(self, X):'+\"\\n\")\nfile.write('        pr = [np.round(np.abs(item[0])) for item in self.clf.predict(X)]'+\"\\n\")\nfile.write('        return pr'+\"\\n\")\nfile.write('    def predict_proba(self, X):'+\"\\n\")\nfile.write('        p_all = []'+\"\\n\")\nfile.write('        p_all.append([1-np.abs(item[0]) for item in self.clf.predict(X)])'+\"\\n\")\nfile.write('        p_all.append([np.abs(item[0]) for item in self.clf.predict(X)])'+\"\\n\")\nfile.write('        return np.transpose(np.array(p_all))'+\"\\n\")\nfile.close()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:13:06.004055Z","iopub.execute_input":"2022-03-19T09:13:06.004641Z","iopub.status.idle":"2022-03-19T09:13:06.013399Z","shell.execute_reply.started":"2022-03-19T09:13:06.004582Z","shell.execute_reply":"2022-03-19T09:13:06.012618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def featex(smis):\n    fname = []\n    fused = []\n    feat0 = featsmi(\"AP2D\",smis);fname.append(\"AP2D\");fused.append(0)\n    feat1 = featsmi(\"CKD\",smis);fname.append(\"CKD\");fused.append(1)\n    feat2 = featsmi(\"CKDExt\",smis);fname.append(\"CKDExt\");fused.append(2)\n    feat3 = featsmi(\"CKDGraph\",smis);fname.append(\"CKDGraph\");fused.append(3)\n    feat4 = featsmi(\"MACCS\",smis);fname.append(\"MACCS\");fused.append(4)\n    feat5 = featsmi(\"PubChem\",smis);fname.append(\"PubChem\");fused.append(5)\n    feat6 = featsmi(\"Estate\",smis);fname.append(\"Estate\");fused.append(6)\n    feat7 = featsmi(\"KR\",smis);fname.append(\"KR\");fused.append(7)\n    feat8 = featsmi(\"FP4\",smis);fname.append(\"FP4\");fused.append(8)\n    feat9 = featsmi(\"FP4C\",smis);fname.append(\"FP4C\");fused.append(9)\n    feat10 = featsmi(\"Circle\",smis);fname.append(\"Circle\");fused.append(10)\n    feat11 = featsmi(\"Hybrid\",smis);fname.append(\"Hybrid\");fused.append(11)\n    allfeat_pos = np.hstack((\n                             feat0, \n                             feat1, \n                             feat2, \n                             feat3, \n                             feat4,\n                             feat5, \n                             feat6, \n                             feat7, \n                             feat8, \n                             feat9,\n                             feat10,\n                             feat11,\n                            ))\n    f = []\n    before = 0\n    for i in fused:\n        after = before + eval('feat%d.shape[1]'% (i))\n        f.append(list(range(before, after)))\n        before = after\n        \n    return allfeat_pos, f, fname ","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:13:06.434142Z","iopub.execute_input":"2022-03-19T09:13:06.434691Z","iopub.status.idle":"2022-03-19T09:13:06.450279Z","shell.execute_reply.started":"2022-03-19T09:13:06.434635Z","shell.execute_reply":"2022-03-19T09:13:06.448911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, f, fname = featex(smiles_tr)\nXt, f, fname = featex(smiles_ts)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:13:20.02136Z","iopub.execute_input":"2022-03-19T09:13:20.02171Z","iopub.status.idle":"2022-03-19T09:13:22.503809Z","shell.execute_reply.started":"2022-03-19T09:13:20.021677Z","shell.execute_reply":"2022-03-19T09:13:22.502695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(X[:,f[9]])\nX[:,f[9]] =  scaler.transform(X[:,f[9]])\nXt[:,f[9]] =  scaler.transform(Xt[:,f[9]])\n\nfrom joblib import dump\ndump(scaler, \"FP4C_Scaler.sav\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[len(i) for i in f]","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:13:24.335985Z","iopub.execute_input":"2022-03-19T09:13:24.336496Z","iopub.status.idle":"2022-03-19T09:13:24.343977Z","shell.execute_reply.started":"2022-03-19T09:13:24.336453Z","shell.execute_reply":"2022-03-19T09:13:24.342849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cname = ['KNN', 'LR', 'PLS', 'SVM', 'RF', 'ET']","metadata":{"execution":{"iopub.status.busy":"2022-03-19T08:28:12.837545Z","iopub.execute_input":"2022-03-19T08:28:12.838466Z","iopub.status.idle":"2022-03-19T08:28:12.843165Z","shell.execute_reply.started":"2022-03-19T08:28:12.838417Z","shell.execute_reply":"2022-03-19T08:28:12.842215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fname","metadata":{"execution":{"iopub.status.busy":"2022-03-19T08:28:23.982582Z","iopub.execute_input":"2022-03-19T08:28:23.983389Z","iopub.status.idle":"2022-03-19T08:28:23.991414Z","shell.execute_reply.started":"2022-03-19T08:28:23.98333Z","shell.execute_reply":"2022-03-19T08:28:23.990016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from joblib import dump\ndump((X, Xt, f, cname, fname), 'rawdata.sav')","metadata":{"execution":{"iopub.status.busy":"2022-03-19T08:30:58.681072Z","iopub.execute_input":"2022-03-19T08:30:58.68142Z","iopub.status.idle":"2022-03-19T08:30:58.941706Z","shell.execute_reply.started":"2022-03-19T08:30:58.681389Z","shell.execute_reply":"2022-03-19T08:30:58.940871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# KNN, LR, PLS, SVM, RF, ET\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom PLS import PLS\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\n\nix = []\nnr_fold = 10\nfor i in range(0, len(y)):\n    ix.append(i)\nix = np.array(ix)\n\nfeatx = []\n\nfor i in range(0,len(f)):\n    feat = np.zeros((len(X),),dtype=float)\n    for j in range(0, nr_fold):\n        Xs = X[:,f[i]]\n        train_ix = ((ix % nr_fold) != j)\n        test_ix = ((ix % nr_fold) == j)\n        train_X, test_X = Xs[train_ix], Xs[test_ix]\n        train_y, test_y = y[train_ix], y[test_ix]\n        clf = KNeighborsClassifier(n_neighbors=1)\n        clf.fit(train_X, train_y)\n        pr = clf.predict_proba(test_X)[:,0]\n        feat[test_ix] = pr    \n    feat = np.reshape(feat,(len(X),1))\n    if (i == 0):\n        featx = feat\n    else:\n        featx = np.concatenate((featx,feat),axis=1)\n\n    feat = np.zeros((len(X),),dtype=float)\n    for j in range(0, nr_fold):\n        Xs = X[:,f[i]]\n        train_ix = ((ix % nr_fold) != j)\n        test_ix = ((ix % nr_fold) == j)\n        train_X, test_X = Xs[train_ix], Xs[test_ix]\n        train_y, test_y = y[train_ix], y[test_ix]\n        clf = LogisticRegression(random_state=0, max_iter=5000)\n        clf.fit(train_X, train_y)\n        pr = clf.predict_proba(test_X)[:,0]\n        feat[test_ix] = pr\n    feat = np.reshape(feat,(len(X),1))\n    featx = np.concatenate((featx,feat),axis=1)\n    \n    feat = np.zeros((len(X),),dtype=float)\n    for j in range(0, nr_fold):\n        Xs = X[:,f[i]]\n        train_ix = ((ix % nr_fold) != j)\n        test_ix = ((ix % nr_fold) == j)\n        train_X, test_X = Xs[train_ix], Xs[test_ix]\n        train_y, test_y = y[train_ix], y[test_ix]\n        clf = PLS()\n        clf.fit(train_X, train_y)\n        pr = clf.predict_proba(test_X)[:,0]\n        feat[test_ix] = pr\n    feat = np.reshape(feat,(len(X),1))\n    featx = np.concatenate((featx,feat),axis=1)\n    \n    feat = np.zeros((len(X),),dtype=float)\n    for j in range(0, nr_fold):\n        Xs = X[:,f[i]]\n        train_ix = ((ix % nr_fold) != j)\n        test_ix = ((ix % nr_fold) == j)\n        train_X, test_X = Xs[train_ix], Xs[test_ix]\n        train_y, test_y = y[train_ix], y[test_ix]\n        clf = SVC(probability=True, random_state=0)\n        clf.fit(train_X, train_y)\n        pr = clf.predict_proba(test_X)[:,0]\n        feat[test_ix] = pr\n    feat = np.reshape(feat,(len(X),1))\n    featx = np.concatenate((featx,feat),axis=1)\n    \n    feat = np.zeros((len(X),),dtype=float)\n    for j in range(0, nr_fold):\n        Xs = X[:,f[i]]\n        train_ix = ((ix % nr_fold) != j)\n        test_ix = ((ix % nr_fold) == j)\n        train_X, test_X = Xs[train_ix], Xs[test_ix]\n        train_y, test_y = y[train_ix], y[test_ix]\n        clf = RandomForestClassifier(random_state=0)\n        clf.fit(train_X, train_y)\n        pr = clf.predict_proba(test_X)[:,0]\n        feat[test_ix] = pr\n    feat = np.reshape(feat,(len(X),1))\n    featx = np.concatenate((featx,feat),axis=1)\n\n    feat = np.zeros((len(X),),dtype=float)\n    for j in range(0, nr_fold):\n        Xs = X[:,f[i]]\n        train_ix = ((ix % nr_fold) != j)\n        test_ix = ((ix % nr_fold) == j)\n        train_X, test_X = Xs[train_ix], Xs[test_ix]\n        train_y, test_y = y[train_ix], y[test_ix]\n        clf = ExtraTreesClassifier(random_state=0)\n        clf.fit(train_X, train_y)\n        pr = clf.predict_proba(test_X)[:,0]\n        feat[test_ix] = pr\n    feat = np.reshape(feat,(len(X),1))\n    featx = np.concatenate((featx,feat),axis=1)\n\nX_train_norm =  featx\n\nfrom sklearn.datasets import dump_svmlight_file\ndump_svmlight_file(X_train_norm,y,'traindata.scl',zero_based=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"featx = []\nallclf = []  \n\nfor i in range(0,len(f)):\n    Xs = X[:,f[i]]\n    Xts = Xt[:,f[i]]\n    \n    clf = KNeighborsClassifier(n_neighbors=1)\n    clf.fit(Xs, y)\n    allclf.append(clf)\n    pr = clf.predict_proba(Xts)[:,0]\n    feat = pr\n    feat = np.reshape(feat,(len(Xts),1))\n    if (i == 0):\n        featx = feat\n    else:\n        featx = np.concatenate((featx,feat),axis=1)\n    \n    clf = LogisticRegression(random_state=0, max_iter=5000)\n    clf.fit(Xs, y)\n    allclf.append(clf)\n    pr = clf.predict_proba(Xts)[:,0]\n    feat = pr\n    feat = np.reshape(feat,(len(Xts),1))\n    featx = np.concatenate((featx,feat),axis=1)\n    \n    clf = PLS()\n    clf.fit(Xs, y)\n    allclf.append(clf)\n    pr = clf.predict_proba(Xts)[:,0]\n    feat = pr\n    feat = np.reshape(feat,(len(Xts),1))\n    featx = np.concatenate((featx,feat),axis=1)\n    \n    clf = SVC(probability=True, random_state=0)\n    clf.fit(Xs, y)\n    allclf.append(clf)\n    pr = clf.predict_proba(Xts)[:,0]\n    feat = pr\n    feat = np.reshape(feat,(len(Xts),1))\n    featx = np.concatenate((featx,feat),axis=1)\n    \n    clf = RandomForestClassifier(random_state=0)\n    clf.fit(Xs, y)\n    allclf.append(clf)\n    pr = clf.predict_proba(Xts)[:,0]\n    feat = pr\n    feat = np.reshape(feat,(len(Xts),1))\n    featx = np.concatenate((featx,feat),axis=1)\n\n    clf = ExtraTreesClassifier(random_state=0)\n    clf.fit(Xs, y)\n    allclf.append(clf)\n    pr = clf.predict_proba(Xts)[:,0]\n    feat = pr\n    feat = np.reshape(feat,(len(Xts),1))\n    featx = np.concatenate((featx,feat),axis=1)\n\n    \nX_test_norm =  featx\ndump_svmlight_file(X_test_norm,yt,'testdata.scl',zero_based=False)\n\n# Save Prob Model\nfrom joblib import dump\ndump(allclf, \"allmodelnuclear.sav\")","metadata":{},"execution_count":null,"outputs":[]}]}