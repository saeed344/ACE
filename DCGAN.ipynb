{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current directory\n",
    "import os\n",
    "os.chdir('F:\\Work\\Experiment\\pLM4ACE\\model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_new = pd.read_csv(r\"fusion_features\\Data\\single\\AAI.csv\", index_col=0, header=None)\n",
    "y_new = pd.read_csv(\"fusion_features\\Data\\label.csv\", index_col=False, header=None)\n",
    "\n",
    "print(X_new.shape)\n",
    "print(y_new.shape)\n",
    "print(np.count_nonzero(y_new==0))\n",
    "print(np.count_nonzero(y_new==1))\n",
    "\n",
    "X_new = np.array(X_new, 'float32')\n",
    "y_new = np.array(y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10折交叉验证\n",
    "import statistics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import scale\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Lambda, Concatenate, Multiply\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import adam_v2\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_whole, X_ind_test, y_train_whole, y_ind_test = train_test_split(X_new, y_new, test_size=0.2, random_state=1111)\n",
    "\n",
    "\n",
    "# X_train_whole = scale(X_train_whole)\n",
    "[sample_num, input_dimwx]=np.shape(X_train_whole)\n",
    "X = X_train_whole\n",
    "y = y_train_whole\n",
    "\n",
    "def build_discriminator():\n",
    "    img = Input(shape=(1,input_dimwx,1))\n",
    "    x = Conv2D(filters=64, kernel_size=(1,9), strides=2, padding='valid', name='conv1')(img)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    \n",
    "    x = Conv2D(filters=32, kernel_size=(1,9), strides=2, padding='valid', name='conv1')(img)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    x = Flatten()(x)\n",
    "    pred = Dense(2, activation='sigmoid')(x)\n",
    "    return Model(img, pred)\n",
    "\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['binary_accuracy'])\n",
    "\n",
    "def build_generator():\n",
    "    noise_shape =(input_dimwx,)\n",
    "    x_noise = Input(shape=noise_shape)\n",
    "    x = Dense(64 * 1 * input_dimwx, activation=\"relu\")(x_noise)\n",
    "    x = Reshape((1, input_dimwx, 64))(x)\n",
    "    x = BatchNormalization(momentum=0.2)(x)\n",
    "    x = UpSampling2D()(x)\n",
    "    [aa1,bb1,cc1,dd1] = x.shape\n",
    "    numx1 = int(cc1//4)\n",
    "    x = Conv2D(32, kernel_size=(2,numx1), padding=\"valid\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(momentum=0.2)(x)\n",
    "    [aa2,bb2,cc2,dd2] = x.shape\n",
    "    numx2 = int(1+cc2-input_dimwx)\n",
    "    x = Conv2D(16, kernel_size=(1,numx2), padding=\"valid\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(momentum=0.2)(x)\n",
    "    x = Conv2D(1, kernel_size=3, padding=\"same\")(x)\n",
    "    gen_out = Activation(\"tanh\")(x)\n",
    "    return Model(x_noise, gen_out)\n",
    "\n",
    "generator = build_generator()\n",
    "generator.compile(loss='binary_crossentropy', optimizer=adam_v2.Adam(0.002, 0.8), metrics=['binary_accuracy'])\n",
    "\n",
    "z = Input(shape=(input_dimwx,))\n",
    "img = generator(z)\n",
    "discriminator.trainable = False\n",
    "valid = discriminator(img)\n",
    "combined = Model(z, valid)\n",
    "combined.compile(loss='binary_crossentropy', optimizer=adam_v2.Adam(0.002, 0.8), metrics=['binary_accuracy'])\n",
    "\n",
    "BACC_collecton = []\n",
    "Sn_collecton = []\n",
    "Sp_collecton = []\n",
    "MCC_collecton = []\n",
    "AUC_collecton = []\n",
    "AP=[]\n",
    "\n",
    "mean_recall = np.linspace(0, 1, 100)\n",
    "all_precision = []\n",
    "base_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr = 0.0\n",
    "# 新的TPR集合\n",
    "interp_tpr_collection = []\n",
    "\n",
    "\n",
    "def categorical_probas_to_classes(p):\n",
    "    return np.argmax(p, axis=1)\n",
    "\n",
    "\n",
    "def to_categorical(y, nb_classes=None):\n",
    "    y = np.array(y, dtype='int')\n",
    "    if not nb_classes:\n",
    "        nb_classes = np.max(y)+1\n",
    "    Y = np.zeros((len(y), nb_classes))\n",
    "    for i in range(len(y)):\n",
    "        Y[i, y[i]] = 1\n",
    "    return Y\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "for train, test in skf.split(X, y):\n",
    "    X_train, X_valid, y_train, y_valid = np.take(X, train.tolist(), axis=0), np.take(X, test.tolist(), axis=0), np.take(y, train.tolist(), axis=0), np.take(y, test.tolist(), axis=0)\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    cv_clf = combined\n",
    "    hist = cv_clf.fit(X_train, y_train, batch_size=64, epochs=60)\n",
    "    y_score = cv_clf.predict(X_valid)\n",
    "    y_class = categorical_probas_to_classes(y_score)\n",
    "    TP, FP, FN, TN = confusion_matrix(y_valid, y_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
    "    Sn_collecton.append(TP/(TP+FN))\n",
    "    Sp_collecton.append(TN/(TN+FP))\n",
    "    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
    "    MCC_collecton.append(MCC)\n",
    "    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
    "    # ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_valid, y_score[:, 1])\n",
    "    interp_tpr = np.interp(base_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    interp_tpr_collection.append(interp_tpr)\n",
    "    auc_roc = auc(fpr, tpr)\n",
    "    AUC_collecton.append(auc_roc)\n",
    "    # PR curve\n",
    "    precision, recall, _ = precision_recall_curve(y_valid, y_score[:, 1])\n",
    "    average_precision = average_precision_score(y_valid, y_score[:, 1])\n",
    "    recall = np.flipud(recall)\n",
    "    precision = np.flipud(precision)\n",
    "\n",
    "    mean_precision = np.interp(mean_recall, recall, precision)\n",
    "    all_precision.append(mean_precision)\n",
    "    AP.append(average_precision)\n",
    "\n",
    "# 输出结果\n",
    "print(round(statistics.mean(BACC_collecton),3),'±',round(statistics.stdev(BACC_collecton),3))\n",
    "print(round(statistics.mean(Sn_collecton),3),'±',round(statistics.stdev(Sn_collecton),3))\n",
    "print(round(statistics.mean(Sp_collecton),3),'±',round(statistics.stdev(Sp_collecton),3))\n",
    "print(round(statistics.mean(MCC_collecton),3),'±',round(statistics.stdev(MCC_collecton),3))\n",
    "print(round(statistics.mean(AUC_collecton),3),'±',round(statistics.stdev(AUC_collecton),3))\n",
    "print(round(statistics.mean(AP),3),'±',round(statistics.stdev(AP),3))\n",
    "\n",
    "# 在所有交叉验证循环结束后，计算TPR的均值\n",
    "mean_tpr = np.mean(interp_tpr_collection, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "\n",
    "# Calculate the mean precision\n",
    "mean_precision = np.mean(all_precision, axis=0)\n",
    "\n",
    "# 保存ROC曲线相关参数\n",
    "np.savez(r'Draw graphics\\ROC curve\\LR_cross_vaild.npz', fpr=base_fpr, tpr=mean_tpr, roc_auc=AUC_collecton)\n",
    "\n",
    "# 保存PR曲线相关参数\n",
    "np.savez(r'Draw graphics\\PR curve\\LR_Indenpendence.npz', recall=mean_recall, precision=mean_precision, average_precision=AP)\n",
    "\n",
    "# 绘制ROC曲线\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(base_fpr, mean_tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % np.mean(AUC_collecton))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('10 k-fold cross vaild')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 独立测试集\n",
    "import statistics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import scale\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Lambda, Concatenate, Multiply\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import adam_v2\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "# X_new = scale(X_new)\n",
    "[sample_num, input_dimwx]=np.shape(X_new)\n",
    "X = X_new\n",
    "y = y_new\n",
    "\n",
    "def build_discriminator():\n",
    "    img = Input(shape=(1,input_dimwx,1))\n",
    "    x = Conv2D(filters=64, kernel_size=(1,9), strides=2, padding='valid', name='conv1')(img)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    \n",
    "    x = Conv2D(filters=32, kernel_size=(1,9), strides=2, padding='valid', name='conv1')(img)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    x = Flatten()(x)\n",
    "    pred = Dense(2, activation='sigmoid')(x)\n",
    "    return Model(img, pred)\n",
    "\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['binary_accuracy'])\n",
    "\n",
    "def build_generator():\n",
    "    noise_shape =(input_dimwx,)\n",
    "    x_noise = Input(shape=noise_shape)\n",
    "    x = Dense(64 * 1 * input_dimwx, activation=\"relu\")(x_noise)\n",
    "    x = Reshape((1, input_dimwx, 64))(x)\n",
    "    x = BatchNormalization(momentum=0.2)(x)\n",
    "    x = UpSampling2D()(x)\n",
    "    [aa1,bb1,cc1,dd1] = x.shape\n",
    "    numx1 = int(cc1//4)\n",
    "    x = Conv2D(32, kernel_size=(2,numx1), padding=\"valid\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(momentum=0.2)(x)\n",
    "    [aa2,bb2,cc2,dd2] = x.shape\n",
    "    numx2 = int(1+cc2-input_dimwx)\n",
    "    x = Conv2D(16, kernel_size=(1,numx2), padding=\"valid\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(momentum=0.2)(x)\n",
    "    x = Conv2D(1, kernel_size=3, padding=\"same\")(x)\n",
    "    gen_out = Activation(\"tanh\")(x)\n",
    "    return Model(x_noise, gen_out)\n",
    "\n",
    "generator = build_generator()\n",
    "generator.compile(loss='binary_crossentropy', optimizer=adam_v2.Adam(0.002, 0.8), metrics=['binary_accuracy'])\n",
    "\n",
    "z = Input(shape=(input_dimwx,))\n",
    "img = generator(z)\n",
    "discriminator.trainable = False\n",
    "valid = discriminator(img)\n",
    "combined = Model(z, valid)\n",
    "combined.compile(loss='binary_crossentropy', optimizer=adam_v2.Adam(0.002, 0.8), metrics=['binary_accuracy'])\n",
    "\n",
    "BACC_collecton = []\n",
    "Sn_collecton = []\n",
    "Sp_collecton = []\n",
    "MCC_collecton = []\n",
    "AUC_collecton = []\n",
    "AP=[]\n",
    "mean_recall = np.linspace(0, 1, 100)\n",
    "all_precision = []\n",
    "\n",
    "base_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr = 0.0\n",
    "# 新的TPR集合\n",
    "interp_tpr_collection = []\n",
    "\n",
    "\n",
    "def categorical_probas_to_classes(p):\n",
    "    return np.argmax(p, axis=1)\n",
    "\n",
    "\n",
    "def to_categorical(y, nb_classes=None):\n",
    "    y = np.array(y, dtype='int')\n",
    "    if not nb_classes:\n",
    "        nb_classes = np.max(y)+1\n",
    "    Y = np.zeros((len(y), nb_classes))\n",
    "    for i in range(len(y)):\n",
    "        Y[i, y[i]] = 1\n",
    "    return Y\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    # dataset splitting\n",
    "    X_train_whole, X_ind_test, y_train_whole, y_ind_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "    y_train_whole = to_categorical(y_train_whole)\n",
    "    cv_clf = combined\n",
    "    hist = cv_clf.fit(X_train_whole, y_train_whole, batch_size=64, epochs=60)\n",
    "    y_score = cv_clf.predict(X_ind_test)\n",
    "    y_class = categorical_probas_to_classes(y_score)\n",
    "    TP, FP, FN, TN = confusion_matrix(y_ind_test, y_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
    "    Sn_collecton.append(TP/(TP+FN))\n",
    "    Sp_collecton.append(TN/(TN+FP))\n",
    "    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
    "    MCC_collecton.append(MCC)\n",
    "    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
    "    # ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_ind_test, y_score[:, 1])\n",
    "    interp_tpr = np.interp(base_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    interp_tpr_collection.append(interp_tpr)\n",
    "    auc_roc = auc(fpr, tpr)\n",
    "    AUC_collecton.append(auc_roc)\n",
    "    # PR curve\n",
    "    precision, recall, _ = precision_recall_curve(y_ind_test, y_score[:, 1])\n",
    "    average_precision = average_precision_score(y_ind_test, y_score[:, 1])\n",
    "    recall = np.flipud(recall)\n",
    "    precision = np.flipud(precision)\n",
    "\n",
    "    mean_precision = np.interp(mean_recall, recall, precision)\n",
    "    all_precision.append(mean_precision)\n",
    "    AP.append(average_precision)\n",
    "\n",
    "# 输出结果\n",
    "print(round(statistics.mean(BACC_collecton),3),'±',round(statistics.stdev(BACC_collecton),3))\n",
    "print(round(statistics.mean(Sn_collecton),3),'±',round(statistics.stdev(Sn_collecton),3))\n",
    "print(round(statistics.mean(Sp_collecton),3),'±',round(statistics.stdev(Sp_collecton),3))\n",
    "print(round(statistics.mean(MCC_collecton),3),'±',round(statistics.stdev(MCC_collecton),3))\n",
    "print(round(statistics.mean(AUC_collecton),3),'±',round(statistics.stdev(AUC_collecton),3))\n",
    "print(round(statistics.mean(AP),3),'±',round(statistics.stdev(AP),3))\n",
    "\n",
    "# 在所有交叉验证循环结束后，计算TPR的均值\n",
    "mean_tpr = np.mean(interp_tpr_collection, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "\n",
    "# Calculate the mean precision\n",
    "mean_precision = np.mean(all_precision, axis=0)\n",
    "\n",
    "# 保存ROC曲线相关参数\n",
    "np.savez(r'Draw graphics\\ROC curve\\LR_cross_vaild.npz', fpr=base_fpr, tpr=mean_tpr, roc_auc=AUC_collecton)\n",
    "\n",
    "# 保存PR曲线相关参数\n",
    "np.savez(r'Draw graphics\\PR curve\\LR_Indenpendence.npz', recall=mean_recall, precision=mean_precision, average_precision=AP)\n",
    "\n",
    "# 绘制ROC曲线\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(base_fpr, mean_tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % np.mean(AUC_collecton))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Independence test')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结尾"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
